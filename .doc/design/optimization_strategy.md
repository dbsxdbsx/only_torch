# 性能优化策略

> 最后更新: 2025-12-20
> 状态: **规划中**
> 适用范围: Only Torch 全局

---

## 项目特点

在讨论优化策略之前，必须明确 Only Torch 的独特定位：

| 特点              | 说明                       | 优化影响                  |
| :---------------- | :------------------------- | :------------------------ |
| **CPU-only**      | 不支持 GPU，专注 CPU 计算  | 无 CUDA，依赖 SIMD/多线程 |
| **NEAT 演化网络** | 网络结构由进化产生，非预设 | 稀疏连接，不规则拓扑      |
| **网络规模较小**  | 进化网络通常几十到几百节点 | 小矩阵运算为主            |
| **结构动态变化**  | 进化过程中拓扑不断改变     | 难以预编译优化            |
| **混合训练模式**  | 进化 + 梯度下降交替        | 需要两种场景都高效        |

---

## 优化维度分析

### 传统深度学习 vs Only Torch

```
传统深度学习优化重点：
┌─────────────────────────────────────────┐
│  GPU 并行  ████████████████████  最重要  │
│  BLAS 优化 ██████████████       高       │
│  Batch 大小 ████████████        高       │
│  算子融合  ████████             中       │
│  多线程    ████                 低       │
└─────────────────────────────────────────┘

Only Torch 优化重点：
┌─────────────────────────────────────────┐
│  个体并行  ████████████████████  最重要  │
│  Batch 训练 ████████████        高       │
│  多线程    ████████████         高       │
│  SIMD      ████████             中       │
│  BLAS      ████                 低       │
└─────────────────────────────────────────┘
```

### 三个关键场景的优化策略

| 场景          | 主要瓶颈               | 最佳优化方向         |
| :------------ | :--------------------- | :------------------- |
| NEAT 进化评估 | 评估大量不同拓扑的个体 | **Rayon 个体间并行** |
| 固定结构训练  | 权重更新的梯度计算     | **Batch + SIMD**     |
| 推理部署      | 单样本延迟             | **编译优化 + 缓存**  |

---

## 优化策略详解

### 策略 1：个体间并行（NEAT 进化阶段）

**场景**：评估种群中的数百个不同网络拓扑。

```rust
// NEAT 进化的核心循环
population.par_iter_mut()  // Rayon 并行
    .for_each(|individual| {
        let fitness = evaluate(individual, &test_data);
        individual.set_fitness(fitness);
    });
```

**为什么有效**：

- 每个个体的网络结构不同，无法 batch 化
- 但个体之间**完全独立**，可完美并行
- 利用多核 CPU，收益 = 核心数 ×

**优先级**：⭐⭐⭐⭐⭐（最高）

---

### 策略 2：Batch 样本间向量化（固定结构训练阶段）

**场景**：网络结构确定后，用梯度下降训练权重。

```rust
// 固定结构的 batch 训练
for batch in data_loader.batches(batch_size) {
    let output = model.forward(&batch)?;  // [batch, ...] 维度向量化
    optimizer.step()?;
}
```

**为什么有效**：

即使 NEAT 网络的单个节点只有少量连接，**batch 维度**的多个样本可以同时计算：

```
传统思维（节点内）：
  node_5 = w_1*x_1 + w_2*x_2  ← 只有2次运算

Batch 思维（样本间）：
  node_5[batch] = w_1*x_1[batch] + w_2*x_2[batch]
                  └── batch 个样本同时计算，可向量化
```

**收益估计**（NEAT 小网络）：3-10x

**优先级**：⭐⭐⭐⭐（高）

---

### 策略 3：SIMD 自动向量化（底层计算）

**场景**：Tensor 层的基础运算。

**当前状态**：

```toml
# Cargo.toml - 当前配置
ndarray = {version="^0.15", features=["serde"]}
# 未启用 BLAS
```

**优化路径**：

| 级别 | 配置                  | 收益  | 复杂度 |
| :--- | :-------------------- | :---- | :----- |
| 基础 | LLVM 自动优化（当前） | 1-3x  | 零     |
| 中级 | 启用 OpenBLAS         | 3-10x | 低     |
| 高级 | Intel MKL（仅 x86）   | 5-20x | 中     |

**建议**：

- MVP 阶段保持现状（LLVM 自动优化）
- 性能调优阶段按需添加 BLAS
- 提供 feature flag 让用户选择

```toml
# 未来可选配置
[features]
default = []
blas-openblas = ["ndarray/blas", "blas-src/openblas"]
blas-mkl = ["ndarray/blas", "blas-src/intel-mkl"]
```

**优先级**：⭐⭐⭐（中）—— 对小矩阵收益有限

---

### 策略 4：内存布局优化

**场景**：NEAT 网络的节点访问模式。

**问题**：进化网络的连接是稀疏且不规则的，导致缓存命中率低。

**优化方向**：

1. **拓扑排序执行**：按依赖顺序计算节点，减少随机访问
2. **节点值连续存储**：所有节点的值放在连续内存中
3. **批量读取连接权重**：同一节点的所有输入权重连续存放

```rust
// 优化前：每个节点单独存储
struct Node {
    value: Tensor,
    weights: Vec<f32>,
}

// 优化后：所有节点值连续存储
struct OptimizedNetwork {
    all_values: Tensor,      // [num_nodes, batch_size]
    all_weights: Vec<f32>,   // 连续存放所有权重
    connection_indices: Vec<(usize, usize)>,  // 连接关系
}
```

**优先级**：⭐⭐（低）—— 后期优化，当前可忽略

---

### 策略 5：编译期优化（远期）

**场景**：网络结构固定后的极致优化。

**思路**：当网络结构确定（进入部署或长期训练），可以将计算图"编译"为优化的执行代码。

```rust
// 概念性代码
let compiled_model = model.compile()?;  // 生成优化的执行路径
for batch in data {
    let output = compiled_model.forward_optimized(&batch)?;
}
```

**可能的优化**：

- 预计算拓扑排序
- 融合连续的线性操作
- 消除中间变量
- 预分配内存

**优先级**：⭐（最低）—— 远期目标

---

## 优化优先级路线图

### MVP 阶段（当前）

| 优化           |   状态    | 说明                |
| :------------- | :-------: | :------------------ |
| Rayon 个体并行 | 🔲 待实现 | NEAT 进化的核心     |
| Batch 训练     | 🔲 待实现 | 需要 ScalarMultiply |
| LLVM 自动优化  |  ✅ 已有  | release 模式自动    |

### 性能调优阶段

| 优化          | 触发条件   | 说明              |
| :------------ | :--------- | :---------------- |
| BLAS 可选支持 | 性能瓶颈   | 添加 feature flag |
| 内存布局优化  | 大规模网络 | 连续存储节点值    |

### 远期阶段

| 优化        | 触发条件 | 说明           |
| :---------- | :------- | :------------- |
| 编译期优化  | 部署需求 | 固定结构后编译 |
| 自定义 SIMD | 极致性能 | 手写关键路径   |

---

## NEAT 网络的向量化收益分布

```
NEAT 网络各部分的向量化潜力：

输入处理:     ████████████  高（batch 输入）
中间节点:     ████          中等（每个节点的 batch 计算）
权重计算:     ██            低（稀疏连接，小矩阵）
输出处理:     ████████████  高（batch 输出）
激活函数:     ████████      高（逐元素，易向量化）
```

**核心认知**：

1. NEAT 网络的向量化收益**主要来自 Batch 维度**
2. 层内/节点内的向量化收益**远低于传统网络**
3. **个体间并行**是 NEAT 场景的最大优化点

---

## 总结

### Only Torch 的优化哲学

```
不追求单个操作的极致性能，
而是追求整体工作流的高效：

  NEAT 进化: 个体并行 >> Batch >> SIMD
  权重训练: Batch >> SIMD >> 个体并行
  推理部署: 编译优化 >> 缓存 >> SIMD
```

### 与传统框架的差异

| 维度     | PyTorch/TensorFlow | Only Torch       |
| :------- | :----------------- | :--------------- |
| 核心假设 | 大规模规则网络     | 小规模不规则网络 |
| 主要并行 | GPU CUDA           | CPU Rayon        |
| 矩阵规模 | 大（数百到数千）   | 小（几个到几十） |
| 结构特点 | 固定层叠加         | 动态进化拓扑     |
| 优化重点 | BLAS/cuBLAS        | 个体并行 + Batch |

### 行动原则

1. **正确性优先**：先保证功能正确，再考虑性能
2. **测量驱动**：用 benchmark 证明瓶颈，而非猜测
3. **渐进优化**：从高收益低复杂度的优化开始
4. **保持简单**：不为假设的未来需求过度工程化
