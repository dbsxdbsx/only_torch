# æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

> æœ€åæ›´æ–°: 2025-12-22
> çŠ¶æ€: **è§„åˆ’ä¸­**
> é€‚ç”¨èŒƒå›´: Only Torch å…¨å±€

---

## é¡¹ç›®ç‰¹ç‚¹

åœ¨è®¨è®ºä¼˜åŒ–ç­–ç•¥ä¹‹å‰ï¼Œå¿…é¡»æ˜ç¡® Only Torch çš„ç‹¬ç‰¹å®šä½ï¼š

| ç‰¹ç‚¹              | è¯´æ˜                       | ä¼˜åŒ–å½±å“                  |
| :---------------- | :------------------------- | :------------------------ |
| **CPU-only**      | ä¸æ”¯æŒ GPUï¼Œä¸“æ³¨ CPU è®¡ç®—  | æ—  CUDAï¼Œä¾èµ– SIMD/å¤šçº¿ç¨‹ |
| **NEAT æ¼”åŒ–ç½‘ç»œ** | ç½‘ç»œç»“æ„ç”±è¿›åŒ–äº§ç”Ÿï¼Œéé¢„è®¾ | ç¨€ç–è¿æ¥ï¼Œä¸è§„åˆ™æ‹“æ‰‘      |
| **ç½‘ç»œè§„æ¨¡è¾ƒå°**  | è¿›åŒ–ç½‘ç»œé€šå¸¸å‡ ååˆ°å‡ ç™¾èŠ‚ç‚¹ | å°çŸ©é˜µè¿ç®—ä¸ºä¸»            |
| **ç»“æ„åŠ¨æ€å˜åŒ–**  | è¿›åŒ–è¿‡ç¨‹ä¸­æ‹“æ‰‘ä¸æ–­æ”¹å˜     | éš¾ä»¥é¢„ç¼–è¯‘ä¼˜åŒ–            |
| **æ··åˆè®­ç»ƒæ¨¡å¼**  | è¿›åŒ– + æ¢¯åº¦ä¸‹é™äº¤æ›¿        | éœ€è¦ä¸¤ç§åœºæ™¯éƒ½é«˜æ•ˆ        |

---

## ä¼˜åŒ–ç»´åº¦åˆ†æ

### ä¼ ç»Ÿæ·±åº¦å­¦ä¹  vs Only Torch

```
ä¼ ç»Ÿæ·±åº¦å­¦ä¹ ä¼˜åŒ–é‡ç‚¹ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU å¹¶è¡Œ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  æœ€é‡è¦  â”‚
â”‚  BLAS ä¼˜åŒ– â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       é«˜       â”‚
â”‚  Batch å¤§å° â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        é«˜       â”‚
â”‚  ç®—å­èåˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             ä¸­       â”‚
â”‚  å¤šçº¿ç¨‹    â–ˆâ–ˆâ–ˆâ–ˆ                 ä½       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Only Torch ä¼˜åŒ–é‡ç‚¹ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¸ªä½“å¹¶è¡Œ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  æœ€é‡è¦  â”‚
â”‚  Batch è®­ç»ƒ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        é«˜       â”‚
â”‚  å¤šçº¿ç¨‹    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         é«˜       â”‚
â”‚  SIMD      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             ä¸­       â”‚
â”‚  BLAS      â–ˆâ–ˆâ–ˆâ–ˆ                 ä½       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸‰ä¸ªå…³é”®åœºæ™¯çš„ä¼˜åŒ–ç­–ç•¥

| åœºæ™¯          | ä¸»è¦ç“¶é¢ˆ               | æœ€ä½³ä¼˜åŒ–æ–¹å‘         |
| :------------ | :--------------------- | :------------------- |
| NEAT è¿›åŒ–è¯„ä¼° | è¯„ä¼°å¤§é‡ä¸åŒæ‹“æ‰‘çš„ä¸ªä½“ | **Rayon ä¸ªä½“é—´å¹¶è¡Œ** |
| å›ºå®šç»“æ„è®­ç»ƒ  | æƒé‡æ›´æ–°çš„æ¢¯åº¦è®¡ç®—     | **Batch + SIMD**     |
| æ¨ç†éƒ¨ç½²      | å•æ ·æœ¬å»¶è¿Ÿ             | **ç¼–è¯‘ä¼˜åŒ– + ç¼“å­˜**  |

---

## ä¼˜åŒ–ç­–ç•¥è¯¦è§£

### ç­–ç•¥ 1ï¼šä¸ªä½“é—´å¹¶è¡Œï¼ˆNEAT è¿›åŒ–é˜¶æ®µï¼‰

**åœºæ™¯**ï¼šè¯„ä¼°ç§ç¾¤ä¸­çš„æ•°ç™¾ä¸ªä¸åŒç½‘ç»œæ‹“æ‰‘ã€‚

```rust
// NEAT è¿›åŒ–çš„æ ¸å¿ƒå¾ªç¯
population.par_iter_mut()  // Rayon å¹¶è¡Œ
    .for_each(|individual| {
        let fitness = evaluate(individual, &test_data);
        individual.set_fitness(fitness);
    });
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š

- æ¯ä¸ªä¸ªä½“çš„ç½‘ç»œç»“æ„ä¸åŒï¼Œæ— æ³• batch åŒ–
- ä½†ä¸ªä½“ä¹‹é—´**å®Œå…¨ç‹¬ç«‹**ï¼Œå¯å®Œç¾å¹¶è¡Œ
- åˆ©ç”¨å¤šæ ¸ CPUï¼Œæ”¶ç›Š = æ ¸å¿ƒæ•° Ã—

**ä¼˜å…ˆçº§**ï¼šâ­â­â­â­â­ï¼ˆæœ€é«˜ï¼‰

---

### ç­–ç•¥ 2ï¼šBatch æ ·æœ¬é—´å‘é‡åŒ–ï¼ˆå›ºå®šç»“æ„è®­ç»ƒé˜¶æ®µï¼‰

**åœºæ™¯**ï¼šç½‘ç»œç»“æ„ç¡®å®šåï¼Œç”¨æ¢¯åº¦ä¸‹é™è®­ç»ƒæƒé‡ã€‚

```rust
// å›ºå®šç»“æ„çš„ batch è®­ç»ƒ
for batch in data_loader.batches(batch_size) {
    let output = model.forward(&batch)?;  // [batch, ...] ç»´åº¦å‘é‡åŒ–
    optimizer.step()?;
}
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š

å³ä½¿ NEAT ç½‘ç»œçš„å•ä¸ªèŠ‚ç‚¹åªæœ‰å°‘é‡è¿æ¥ï¼Œ**batch ç»´åº¦**çš„å¤šä¸ªæ ·æœ¬å¯ä»¥åŒæ—¶è®¡ç®—ï¼š

```
ä¼ ç»Ÿæ€ç»´ï¼ˆèŠ‚ç‚¹å†…ï¼‰ï¼š
  node_5 = w_1*x_1 + w_2*x_2  â† åªæœ‰2æ¬¡è¿ç®—

Batch æ€ç»´ï¼ˆæ ·æœ¬é—´ï¼‰ï¼š
  node_5[batch] = w_1*x_1[batch] + w_2*x_2[batch]
                  â””â”€â”€ batch ä¸ªæ ·æœ¬åŒæ—¶è®¡ç®—ï¼Œå¯å‘é‡åŒ–
```

**æ”¶ç›Šä¼°è®¡**ï¼ˆNEAT å°ç½‘ç»œï¼‰ï¼š3-10x

**ä¼˜å…ˆçº§**ï¼šâ­â­â­â­ï¼ˆé«˜ï¼‰

---

### ç­–ç•¥ 3ï¼šSIMD è‡ªåŠ¨å‘é‡åŒ–ï¼ˆåº•å±‚è®¡ç®—ï¼‰

**åœºæ™¯**ï¼šTensor å±‚çš„åŸºç¡€è¿ç®—ã€‚

**å½“å‰çŠ¶æ€**ï¼š

```toml
# Cargo.toml - å½“å‰é…ç½®
ndarray = {version="^0.15", features=["serde"]}
# æœªå¯ç”¨ BLAS
```

**ä¼˜åŒ–è·¯å¾„**ï¼š

| çº§åˆ« | é…ç½®                  | æ”¶ç›Š  | å¤æ‚åº¦ |
| :--- | :-------------------- | :---- | :----- |
| åŸºç¡€ | LLVM è‡ªåŠ¨ä¼˜åŒ–ï¼ˆå½“å‰ï¼‰ | 1-3x  | é›¶     |
| ä¸­çº§ | å¯ç”¨ OpenBLAS         | 3-10x | ä½     |
| é«˜çº§ | Intel MKLï¼ˆä»… x86ï¼‰   | 5-20x | ä¸­     |

**å»ºè®®**ï¼š

- MVP é˜¶æ®µä¿æŒç°çŠ¶ï¼ˆLLVM è‡ªåŠ¨ä¼˜åŒ–ï¼‰
- æ€§èƒ½è°ƒä¼˜é˜¶æ®µæŒ‰éœ€æ·»åŠ  BLAS
- æä¾› feature flag è®©ç”¨æˆ·é€‰æ‹©

```toml
# æœªæ¥å¯é€‰é…ç½®
[features]
default = []
blas-openblas = ["ndarray/blas", "blas-src/openblas"]
blas-mkl = ["ndarray/blas", "blas-src/intel-mkl"]
```

**ä¼˜å…ˆçº§**ï¼šâ­â­â­ï¼ˆä¸­ï¼‰â€”â€” å¯¹å°çŸ©é˜µæ”¶ç›Šæœ‰é™

---

### ç­–ç•¥ 4ï¼šå†…å­˜å¸ƒå±€ä¼˜åŒ–

**åœºæ™¯**ï¼šNEAT ç½‘ç»œçš„èŠ‚ç‚¹è®¿é—®æ¨¡å¼ã€‚

**é—®é¢˜**ï¼šè¿›åŒ–ç½‘ç»œçš„è¿æ¥æ˜¯ç¨€ç–ä¸”ä¸è§„åˆ™çš„ï¼Œå¯¼è‡´ç¼“å­˜å‘½ä¸­ç‡ä½ã€‚

**ä¼˜åŒ–æ–¹å‘**ï¼š

1. **æ‹“æ‰‘æ’åºæ‰§è¡Œ**ï¼šæŒ‰ä¾èµ–é¡ºåºè®¡ç®—èŠ‚ç‚¹ï¼Œå‡å°‘éšæœºè®¿é—®
2. **èŠ‚ç‚¹å€¼è¿ç»­å­˜å‚¨**ï¼šæ‰€æœ‰èŠ‚ç‚¹çš„å€¼æ”¾åœ¨è¿ç»­å†…å­˜ä¸­
3. **æ‰¹é‡è¯»å–è¿æ¥æƒé‡**ï¼šåŒä¸€èŠ‚ç‚¹çš„æ‰€æœ‰è¾“å…¥æƒé‡è¿ç»­å­˜æ”¾

```rust
// ä¼˜åŒ–å‰ï¼šæ¯ä¸ªèŠ‚ç‚¹å•ç‹¬å­˜å‚¨
struct Node {
    value: Tensor,
    weights: Vec<f32>,
}

// ä¼˜åŒ–åï¼šæ‰€æœ‰èŠ‚ç‚¹å€¼è¿ç»­å­˜å‚¨
struct OptimizedNetwork {
    all_values: Tensor,      // [num_nodes, batch_size]
    all_weights: Vec<f32>,   // è¿ç»­å­˜æ”¾æ‰€æœ‰æƒé‡
    connection_indices: Vec<(usize, usize)>,  // è¿æ¥å…³ç³»
}
```

**ä¼˜å…ˆçº§**ï¼šâ­â­ï¼ˆä½ï¼‰â€”â€” åæœŸä¼˜åŒ–ï¼Œå½“å‰å¯å¿½ç•¥

---

### ç­–ç•¥ 5ï¼šç¼–è¯‘æœŸä¼˜åŒ–ï¼ˆè¿œæœŸï¼‰

**åœºæ™¯**ï¼šç½‘ç»œç»“æ„å›ºå®šåçš„æè‡´ä¼˜åŒ–ã€‚

**æ€è·¯**ï¼šå½“ç½‘ç»œç»“æ„ç¡®å®šï¼ˆè¿›å…¥éƒ¨ç½²æˆ–é•¿æœŸè®­ç»ƒï¼‰ï¼Œå¯ä»¥å°†è®¡ç®—å›¾"ç¼–è¯‘"ä¸ºä¼˜åŒ–çš„æ‰§è¡Œä»£ç ã€‚

```rust
// æ¦‚å¿µæ€§ä»£ç 
let compiled_model = model.compile()?;  // ç”Ÿæˆä¼˜åŒ–çš„æ‰§è¡Œè·¯å¾„
for batch in data {
    let output = compiled_model.forward_optimized(&batch)?;
}
```

**å¯èƒ½çš„ä¼˜åŒ–**ï¼š

- é¢„è®¡ç®—æ‹“æ‰‘æ’åº
- èåˆè¿ç»­çš„çº¿æ€§æ“ä½œ
- æ¶ˆé™¤ä¸­é—´å˜é‡
- é¢„åˆ†é…å†…å­˜

**ä¼˜å…ˆçº§**ï¼šâ­ï¼ˆæœ€ä½ï¼‰â€”â€” è¿œæœŸç›®æ ‡

---

## ä¼˜åŒ–ä¼˜å…ˆçº§è·¯çº¿å›¾

### MVP é˜¶æ®µï¼ˆå½“å‰ï¼‰

| ä¼˜åŒ–           |   çŠ¶æ€    | è¯´æ˜                                                        |
| :------------- | :-------: | :---------------------------------------------------------- |
| Rayon ä¸ªä½“å¹¶è¡Œ | ğŸ”² å¾…å®ç° | NEAT è¿›åŒ–çš„æ ¸å¿ƒ                                             |
| Batch è®­ç»ƒ     | ğŸ”² å¾…å®ç° | è¯¦è§ [batch_mechanism_design.md](batch_mechanism_design.md) |
| LLVM è‡ªåŠ¨ä¼˜åŒ–  |  âœ… å·²æœ‰  | release æ¨¡å¼è‡ªåŠ¨                                            |

### æ€§èƒ½è°ƒä¼˜é˜¶æ®µ

| ä¼˜åŒ–          | è§¦å‘æ¡ä»¶   | è¯´æ˜              |
| :------------ | :--------- | :---------------- |
| BLAS å¯é€‰æ”¯æŒ | æ€§èƒ½ç“¶é¢ˆ   | æ·»åŠ  feature flag |
| å†…å­˜å¸ƒå±€ä¼˜åŒ–  | å¤§è§„æ¨¡ç½‘ç»œ | è¿ç»­å­˜å‚¨èŠ‚ç‚¹å€¼    |

### è¿œæœŸé˜¶æ®µ

| ä¼˜åŒ–        | è§¦å‘æ¡ä»¶ | è¯´æ˜           |
| :---------- | :------- | :------------- |
| ç¼–è¯‘æœŸä¼˜åŒ–  | éƒ¨ç½²éœ€æ±‚ | å›ºå®šç»“æ„åç¼–è¯‘ |
| è‡ªå®šä¹‰ SIMD | æè‡´æ€§èƒ½ | æ‰‹å†™å…³é”®è·¯å¾„   |

---

## NEAT ç½‘ç»œçš„å‘é‡åŒ–æ”¶ç›Šåˆ†å¸ƒ

```
NEAT ç½‘ç»œå„éƒ¨åˆ†çš„å‘é‡åŒ–æ½œåŠ›ï¼š

è¾“å…¥å¤„ç†:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  é«˜ï¼ˆbatch è¾“å…¥ï¼‰
ä¸­é—´èŠ‚ç‚¹:     â–ˆâ–ˆâ–ˆâ–ˆ          ä¸­ç­‰ï¼ˆæ¯ä¸ªèŠ‚ç‚¹çš„ batch è®¡ç®—ï¼‰
æƒé‡è®¡ç®—:     â–ˆâ–ˆ            ä½ï¼ˆç¨€ç–è¿æ¥ï¼Œå°çŸ©é˜µï¼‰
è¾“å‡ºå¤„ç†:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  é«˜ï¼ˆbatch è¾“å‡ºï¼‰
æ¿€æ´»å‡½æ•°:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      é«˜ï¼ˆé€å…ƒç´ ï¼Œæ˜“å‘é‡åŒ–ï¼‰
```

**æ ¸å¿ƒè®¤çŸ¥**ï¼š

1. NEAT ç½‘ç»œçš„å‘é‡åŒ–æ”¶ç›Š**ä¸»è¦æ¥è‡ª Batch ç»´åº¦**
2. å±‚å†…/èŠ‚ç‚¹å†…çš„å‘é‡åŒ–æ”¶ç›Š**è¿œä½äºä¼ ç»Ÿç½‘ç»œ**
3. **ä¸ªä½“é—´å¹¶è¡Œ**æ˜¯ NEAT åœºæ™¯çš„æœ€å¤§ä¼˜åŒ–ç‚¹

---

## æ€»ç»“

### Only Torch çš„ä¼˜åŒ–å“²å­¦

```
ä¸è¿½æ±‚å•ä¸ªæ“ä½œçš„æè‡´æ€§èƒ½ï¼Œ
è€Œæ˜¯è¿½æ±‚æ•´ä½“å·¥ä½œæµçš„é«˜æ•ˆï¼š

  NEAT è¿›åŒ–: ä¸ªä½“å¹¶è¡Œ >> Batch >> SIMD
  æƒé‡è®­ç»ƒ: Batch >> SIMD >> ä¸ªä½“å¹¶è¡Œ
  æ¨ç†éƒ¨ç½²: ç¼–è¯‘ä¼˜åŒ– >> ç¼“å­˜ >> SIMD
```

### ä¸ä¼ ç»Ÿæ¡†æ¶çš„å·®å¼‚

| ç»´åº¦     | PyTorch/TensorFlow | Only Torch       |
| :------- | :----------------- | :--------------- |
| æ ¸å¿ƒå‡è®¾ | å¤§è§„æ¨¡è§„åˆ™ç½‘ç»œ     | å°è§„æ¨¡ä¸è§„åˆ™ç½‘ç»œ |
| ä¸»è¦å¹¶è¡Œ | GPU CUDA           | CPU Rayon        |
| çŸ©é˜µè§„æ¨¡ | å¤§ï¼ˆæ•°ç™¾åˆ°æ•°åƒï¼‰   | å°ï¼ˆå‡ ä¸ªåˆ°å‡ åï¼‰ |
| ç»“æ„ç‰¹ç‚¹ | å›ºå®šå±‚å åŠ          | åŠ¨æ€è¿›åŒ–æ‹“æ‰‘     |
| ä¼˜åŒ–é‡ç‚¹ | BLAS/cuBLAS        | ä¸ªä½“å¹¶è¡Œ + Batch |

### è¡ŒåŠ¨åŸåˆ™

1. **æ­£ç¡®æ€§ä¼˜å…ˆ**ï¼šå…ˆä¿è¯åŠŸèƒ½æ­£ç¡®ï¼Œå†è€ƒè™‘æ€§èƒ½
2. **æµ‹é‡é©±åŠ¨**ï¼šç”¨ benchmark è¯æ˜ç“¶é¢ˆï¼Œè€ŒéçŒœæµ‹
3. **æ¸è¿›ä¼˜åŒ–**ï¼šä»é«˜æ”¶ç›Šä½å¤æ‚åº¦çš„ä¼˜åŒ–å¼€å§‹
4. **ä¿æŒç®€å•**ï¼šä¸ä¸ºå‡è®¾çš„æœªæ¥éœ€æ±‚è¿‡åº¦å·¥ç¨‹åŒ–

---

## é™„å½•ï¼šPyTorch CPU å†…æ ¸ä¼˜åŒ–æŠ€æœ¯å‚è€ƒ

> ä»¥ä¸‹æŠ€æœ¯æ¥æºäº PyTorch ATen CPU å†…æ ¸ï¼ˆ`aten/src/ATen/native/cpu/`ï¼‰ï¼Œå¯ä½œä¸ºæœªæ¥ä¼˜åŒ–å‚è€ƒã€‚

### 1. å¹¶è¡ŒåŒ–æŠ€æœ¯

**PyTorch å®ç°** (`at::parallel_for`)ï¼š

```cpp
// PyTorch: AvgPoolKernel.cpp
at::parallel_for(0, channels, 0, [&](int64_t begin, int64_t end) {
    for (const auto c : c10::irange(begin, end)) {
        // æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€éƒ¨åˆ† channels
    }
});
```

**Rust å¯¹åº”æ–¹æ¡ˆ**ï¼š

| PyTorch                                   | Rust ç­‰ä»·                                  | è¯´æ˜                   |
| ----------------------------------------- | ------------------------------------------ | ---------------------- |
| `at::parallel_for`                        | [`rayon::par_iter`](https://docs.rs/rayon) | æ•°æ®å¹¶è¡Œï¼Œè‡ªåŠ¨è´Ÿè½½å‡è¡¡ |
| `at::parallel_for(0, n, grain_size, ...)` | `rayon::iter::with_min_len()`              | æ§åˆ¶æœ€å°åˆ†å—å¤§å°       |

```rust
// Rust ç­‰ä»·å®ç°
use rayon::prelude::*;

// åŸºç¡€ç”¨æ³•
(0..channels).into_par_iter().for_each(|c| {
    // æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€éƒ¨åˆ† channels
});

// å¸¦æœ€å°åˆ†å—å¤§å°ï¼ˆç±»ä¼¼ grain_sizeï¼‰
(0..channels)
    .into_par_iter()
    .with_min_len(64)  // æ¯ä¸ªä»»åŠ¡è‡³å°‘å¤„ç† 64 ä¸ªå…ƒç´ 
    .for_each(|c| { /* ... */ });
```

---

### 2. SIMD å‘é‡åŒ–æŠ€æœ¯

**PyTorch å®ç°** (`vec::Vectorized`)ï¼š

```cpp
// PyTorch: MaxPoolKernel.cpp
using Vec = vec::Vectorized<scalar_t>;

int64_t d = 0;
for (; d < len; d += Vec::size()) {
    Vec val_vec = Vec::loadu(in + d);        // SIMD åŠ è½½
    Vec max_vec = Vec::loadu(out + d);
    Vec result = Vec::blendv(max_vec, val_vec, val_vec > max_vec);
    result.store(out + d);                    // SIMD å­˜å‚¨
}
// å¤„ç†å°¾éƒ¨ï¼ˆä¸è¶³ä¸€ä¸ª SIMD å®½åº¦ï¼‰
for (; d < size; d++) {
    out[d] = std::max(out[d], in[d]);
}
```

**Rust å¯¹åº”æ–¹æ¡ˆ**ï¼š

| PyTorch              | Rust ç­‰ä»·                                                    | è¯´æ˜                  |
| -------------------- | ------------------------------------------------------------ | --------------------- |
| `vec::Vectorized<T>` | [`std::simd`](https://doc.rust-lang.org/std/simd/) (nightly) | æ ‡å‡†åº“ SIMDï¼ˆå®éªŒæ€§ï¼‰ |
|                      | [`wide`](https://docs.rs/wide) crate                         | ç¨³å®šç‰ˆè·¨å¹³å° SIMD     |
|                      | [`packed_simd`](https://docs.rs/packed_simd)                 | æ›´åº•å±‚çš„ SIMD æ§åˆ¶    |
|                      | [`pulp`](https://docs.rs/pulp)                               | è‡ªåŠ¨ SIMD åˆ†å‘        |

```rust
// æ–¹æ¡ˆ 1: wide crateï¼ˆæ¨èï¼Œç¨³å®šç‰ˆå¯ç”¨ï¼‰
use wide::f32x8;

let mut d = 0;
while d + 8 <= len {
    let val = f32x8::from(&input[d..d+8]);
    let max = f32x8::from(&output[d..d+8]);
    let result = val.max(max);
    result.store(&mut output[d..d+8]);
    d += 8;
}
// å°¾éƒ¨æ ‡é‡å¤„ç†
for i in d..len {
    output[i] = output[i].max(input[i]);
}

// æ–¹æ¡ˆ 2: std::simdï¼ˆnightlyï¼Œæœªæ¥æ ‡å‡†ï¼‰
#![feature(portable_simd)]
use std::simd::{f32x8, SimdFloat};

let val = f32x8::from_slice(&input[d..]);
let max = f32x8::from_slice(&output[d..]);
let result = val.simd_max(max);
```

**å¸¸ç”¨ SIMD æ“ä½œå¯¹ç…§è¡¨**ï¼š

| æ“ä½œ     | PyTorch `vec::Vectorized` | Rust `wide` / `std::simd` |
| -------- | ------------------------- | ------------------------- |
| åŠ è½½     | `Vec::loadu(ptr)`         | `f32x8::from(slice)`      |
| å­˜å‚¨     | `vec.store(ptr)`          | `vec.store(slice)`        |
| åŠ æ³•     | `a + b`                   | `a + b`                   |
| ä¹˜æ³•     | `a * b`                   | `a * b`                   |
| æœ€å¤§å€¼   | `Vec::max(a, b)`          | `a.max(b)`                |
| æ¡ä»¶é€‰æ‹© | `Vec::blendv(a, b, mask)` | `mask.select(b, a)`       |
| æ°´å¹³æ±‚å’Œ | `vec.reduce_add()`        | `vec.reduce_add()`        |

---

### 3. å†…å­˜å¸ƒå±€ä¼˜åŒ–

**PyTorch ç­–ç•¥**ï¼š

```cpp
// PyTorch æ”¯æŒå¤šç§å†…å­˜å¸ƒå±€
auto input = input_.contiguous();                      // NCHW (é»˜è®¤)
auto input = input_.contiguous(MemoryFormat::ChannelsLast);  // NHWC

// Channels Last å¯¹ SIMD æ›´å‹å¥½ï¼ˆè¿ç»­è®¿é—® channel ç»´åº¦ï¼‰
```

**Rust å¯¹åº”æ–¹æ¡ˆ**ï¼š

```rust
// ndarray æ”¯æŒä¸åŒå†…å­˜å¸ƒå±€
use ndarray::{Array4, Axis};

// C é¡ºåºï¼ˆNCHWï¼Œè¡Œä¼˜å…ˆï¼‰â€”â€” é»˜è®¤
let tensor = Array4::<f32>::zeros((batch, channels, height, width));

// Fortran é¡ºåºï¼ˆåˆ—ä¼˜å…ˆï¼‰
let tensor = Array4::<f32>::zeros((batch, channels, height, width).f());

// è½¬æ¢å¸ƒå±€
let contiguous = tensor.as_standard_layout().to_owned();
```

---

### 4. æ•°æ®ç±»å‹ä¼˜åŒ–

**PyTorch å®ç°**ï¼š

```cpp
// PyTorch å¯¹ BFloat16/Half ä½¿ç”¨ float ç´¯åŠ ï¼Œé¿å…ç²¾åº¦æŸå¤±
using opmath_t = at::opmath_type<scalar_t>;  // scalar_t=bf16 â†’ opmath_t=f32

opmath_t sum = 0;
for (...) {
    sum += opmath_t(input[i]);  // ç´¯åŠ æ—¶æå‡ç²¾åº¦
}
output[i] = scalar_t(sum / count);  // è¾“å‡ºæ—¶é™å›åŸç²¾åº¦
```

**Rust å¯¹åº”æ–¹æ¡ˆ**ï¼š

```rust
// ä½¿ç”¨ half crate å¤„ç†åŠç²¾åº¦
use half::{bf16, f16};

// ç´¯åŠ æ—¶ä½¿ç”¨ f32
let sum: f32 = input.iter()
    .map(|&x| f32::from(x))  // bf16 â†’ f32
    .sum();
let avg = bf16::from_f32(sum / count as f32);  // f32 â†’ bf16
```

---

### 5. ç´¢å¼•ä¼˜åŒ–æŠ€æœ¯

**PyTorch å®ç°**ï¼ˆé¿å…å¤šç»´ç´¢å¼•è®¡ç®—ï¼‰ï¼š

```cpp
// PyTorch: é¢„è®¡ç®—åç§»é‡ï¼Œé¿å…é‡å¤ç´¢å¼•è®¡ç®—
int64_t index = id * input_height * input_width + ih * input_width + iw;
const scalar_t* in = input_data + n * input_depth * input_height * input_width;
```

**Rust å¯¹åº”æ–¹æ¡ˆ**ï¼š

```rust
// ä½¿ç”¨ unsafe æŒ‡é’ˆè¿ç®—ï¼ˆæ€§èƒ½æ•æ„Ÿè·¯å¾„ï¼‰
let base_offset = n * depth * height * width;
let idx = base_offset + d * height * width + h * width + w;

// æˆ–ä½¿ç”¨ ndarray çš„é«˜æ•ˆç´¢å¼•
use ndarray::s;
let slice = tensor.slice(s![n, .., h0..h1, w0..w1]);
```

---

### 6. å°¾éƒ¨å¤„ç†æ¨¡å¼

**é€šç”¨æ¨¡å¼**ï¼ˆPyTorch å’Œ Rust é€šç”¨ï¼‰ï¼š

```rust
// SIMD å®½åº¦å¯¹é½ + å°¾éƒ¨æ ‡é‡å¤„ç†
let simd_width = 8;  // å¦‚ f32x8
let aligned_len = (len / simd_width) * simd_width;

// SIMD å¤„ç†å¯¹é½éƒ¨åˆ†
for i in (0..aligned_len).step_by(simd_width) {
    // SIMD æ“ä½œ
}

// æ ‡é‡å¤„ç†å°¾éƒ¨
for i in aligned_len..len {
    // æ ‡é‡æ“ä½œ
}
```

---

### ç›¸å…³ Rust Crate æ±‡æ€»

| ç”¨é€”        | Crate                  | è¯´æ˜                  |
| ----------- | ---------------------- | --------------------- |
| å¹¶è¡Œè¿­ä»£    | `rayon`                | æ•°æ®å¹¶è¡Œï¼Œç±»ä¼¼ OpenMP |
| SIMD (ç¨³å®š) | `wide`                 | è·¨å¹³å° SIMD æŠ½è±¡      |
| SIMD (åº•å±‚) | `packed_simd`          | æ›´ç»†ç²’åº¦æ§åˆ¶          |
| SIMD (å®éªŒ) | `std::simd`            | æœªæ¥æ ‡å‡†ï¼ˆnightlyï¼‰   |
| åŠç²¾åº¦æµ®ç‚¹  | `half`                 | f16/bf16 æ”¯æŒ         |
| BLAS        | `ndarray` + `blas-src` | çº¿æ€§ä»£æ•°åŠ é€Ÿ          |
| å†…å­˜å¯¹é½    | `aligned`              | å¯¹é½å†…å­˜åˆ†é…          |
