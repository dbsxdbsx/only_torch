/*
 * @Author       : è€è‘£
 * @Date         : 2025-07-24 16:00:00
 * @LastEditors  : è€è‘£
 * @LastEditTime : 2025-07-24 16:00:00
 * @Description  : ä¼˜åŒ–å™¨ç¤ºä¾‹æµ‹è¯•ï¼Œå‚è€ƒè‡ªï¼šhttps://github.com/zc911/MatrixSlow/blob/master/example/ch03/optimizer_example.py
 */

use only_torch::nn::optimizer::{Optimizer, SGD};
use only_torch::nn::{Graph, GraphError, VarActivationOps, VarLossOps, VarMatrixOps};
use only_torch::tensor::Tensor;
use only_torch::{tensor_slice, tensor_where};

#[test]
fn test_optimizer_example() -> Result<(), GraphError> {
    let start_time = std::time::Instant::now();

    // æ„é€ è®­ç»ƒæ•°æ®ï¼ˆä½¿ç”¨å›ºå®šç§å­ç¡®ä¿æµ‹è¯•å¯é‡å¤æ€§ï¼‰
    let seed_base: u64 = 42;
    let male_heights = Tensor::normal_seeded(171.0, 6.0, &[500], seed_base);
    let female_heights = Tensor::normal_seeded(158.0, 5.0, &[500], seed_base + 1);

    let male_weights = Tensor::normal_seeded(70.0, 10.0, &[500], seed_base + 2);
    let female_weights = Tensor::normal_seeded(57.0, 8.0, &[500], seed_base + 3);

    let male_bfrs = Tensor::normal_seeded(16.0, 2.0, &[500], seed_base + 4);
    let female_bfrs = Tensor::normal_seeded(22.0, 2.0, &[500], seed_base + 5);

    let male_labels = Tensor::new(&[1.0; 500], &[500]);
    let female_labels = Tensor::new(&[-1.0; 500], &[500]);

    let mut train_set = Tensor::stack(
        &[
            &Tensor::stack(&[&male_heights, &female_heights], false),
            &Tensor::stack(&[&male_weights, &female_weights], false),
            &Tensor::stack(&[&male_bfrs, &female_bfrs], false),
            &Tensor::stack(&[&male_labels, &female_labels], false),
        ],
        true,
    );
    train_set.permute_mut(&[1, 0]);
    train_set.shuffle_mut_seeded(Some(0), seed_base + 6); // ä½¿ç”¨å›ºå®šç§å­æ‰“ä¹±æ ·æœ¬é¡ºåº
    println!("è®­ç»ƒé›†å½¢çŠ¶: {:?}", train_set.shape());

    // åˆ›å»ºè®¡ç®—å›¾
    let graph = Graph::new();

    // æ„é€ è®¡ç®—å›¾ï¼šè¾“å…¥å‘é‡ï¼Œæ˜¯ä¸€ä¸ª3x1çŸ©é˜µï¼Œä¸éœ€è¦åˆå§‹åŒ–ï¼Œä¸å‚ä¸è®­ç»ƒ
    let x = graph.zeros(&[3, 1])?;

    // ç±»åˆ«æ ‡ç­¾ï¼Œ1ç”·ï¼Œ-1å¥³
    let label = graph.zeros(&[1, 1])?;

    // æƒé‡å‘é‡ï¼Œæ˜¯ä¸€ä¸ª1x3çŸ©é˜µï¼Œéœ€è¦åˆå§‹åŒ–ï¼Œå‚ä¸è®­ç»ƒ
    let w = graph.parameter_seeded(&[1, 3], "w", seed_base + 7)?;

    // é˜ˆå€¼ï¼Œæ˜¯ä¸€ä¸ª1x1çŸ©é˜µï¼Œéœ€è¦åˆå§‹åŒ–ï¼Œå‚ä¸è®­ç»ƒ
    let b = graph.parameter_seeded(&[1, 1], "b", seed_base + 8)?;

    // ADALINEçš„é¢„æµ‹è¾“å‡º
    let wx = w.matmul(&x)?;
    let output = &wx + &b;
    let predict = output.step();

    // æŸå¤±å‡½æ•°ï¼šä½¿ç”¨MatMulèŠ‚ç‚¹è¿æ¥labelå’Œoutputï¼Œä¿æŒæ¢¯åº¦é“¾å®Œæ•´
    let loss_input = label.matmul(&output)?;
    let loss = loss_input.perception_loss();

    // å­¦ä¹ ç‡ï¼ˆä¸Pythonç‰ˆæœ¬ä¸€è‡´ï¼‰
    // æ³¨æ„ï¼šæ–° API ä¸åšæ¢¯åº¦å¹³å‡ï¼Œæ‰€ä»¥é™¤ä»¥ mini_batch_size æ¥ä¿æŒç­‰æ•ˆ
    let learning_rate = 0.0001;
    let mini_batch_size = 8;
    let scaled_lr = learning_rate / mini_batch_size as f32;

    // åˆ›å»ºSGDä¼˜åŒ–å™¨
    let params = vec![w.clone(), b.clone()];
    let mut optimizer = SGD::new(&graph, &params, scaled_lr);

    // mini batchå‚æ•°
    let mut cur_batch_size = 0;

    // æµ‹è¯•å‚æ•°ï¼ˆä¸test_adaline.rsä¸€è‡´ï¼‰
    let max_epochs = 100;
    let target_accuracy = 0.95; // 95%
    let consecutive_success_required = 3;
    let mut consecutive_success_count = 0;
    let mut test_passed = false;

    // è®­ç»ƒæ‰§è¡Œæœ€å¤š50ä¸ªepochï¼Œæˆ–ç›´åˆ°è¾¾åˆ°æˆåŠŸæ¡ä»¶
    for epoch in 0..max_epochs {
        // éå†è®­ç»ƒé›†ä¸­çš„æ ·æœ¬
        for i in 0..train_set.shape()[0] {
            // å–ç¬¬iä¸ªæ ·æœ¬çš„å‰3åˆ—ï¼ˆé™¤æœ€åä¸€åˆ—çš„æ‰€æœ‰åˆ—ï¼‰ï¼Œæ„é€ 3x1çŸ©é˜µå¯¹è±¡
            let features = tensor_slice!(train_set, i, 0..3).transpose();

            // å–ç¬¬iä¸ªæ ·æœ¬çš„æœ€åä¸€åˆ—ï¼Œæ˜¯è¯¥æ ·æœ¬çš„æ€§åˆ«æ ‡ç­¾ï¼ˆ1ç”·ï¼Œ-1å¥³ï¼‰ï¼Œæ„é€ 1x1çŸ©é˜µå¯¹è±¡
            let l = tensor_slice!(train_set, i, 3);

            // å°†ç‰¹å¾èµ‹ç»™xèŠ‚ç‚¹ï¼Œå°†æ ‡ç­¾èµ‹ç»™labelèŠ‚ç‚¹
            x.set_value(&features)?;
            label.set_value(&l)?;

            // å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼ˆæ¢¯åº¦ä¼šç´¯ç§¯ï¼‰
            loss.backward()?;
            cur_batch_size += 1;

            // å½“ç§¯ç´¯åˆ°ä¸€ä¸ª mini batch çš„æ—¶å€™ï¼Œå®Œæˆä¸€æ¬¡å‚æ•°æ›´æ–°
            if cur_batch_size == mini_batch_size {
                // åœ¨ç¬¬ä¸€ä¸ª epoch çš„ç¬¬ä¸€ä¸ª batch æ‰“å°è°ƒè¯•ä¿¡æ¯
                if epoch == 0 && i < mini_batch_size {
                    println!(
                        "æ›´æ–°å‰ w: {:?}",
                        w.value()?.unwrap().get(&[0, 0])
                    );
                    println!(
                        "æ›´æ–°å‰ b: {:?}",
                        b.value()?.unwrap().get(&[0, 0])
                    );
                }

                optimizer.step()?;
                graph.zero_grad()?;

                if epoch == 0 && i < mini_batch_size {
                    println!(
                        "æ›´æ–°å w: {:?}",
                        w.value()?.unwrap().get(&[0, 0])
                    );
                    println!(
                        "æ›´æ–°å b: {:?}",
                        b.value()?.unwrap().get(&[0, 0])
                    );
                }

                cur_batch_size = 0;
            }
        }

        // å¤„ç†æœ€åä¸å®Œæ•´çš„ batch
        if cur_batch_size > 0 {
            optimizer.step()?;
            graph.zero_grad()?;
            cur_batch_size = 0;
        }

        // æ¯ä¸ªepochç»“æŸåè¯„ä»·æ¨¡å‹çš„æ­£ç¡®ç‡
        let mut pred_vec = Vec::new();

        // éå†è®­ç»ƒé›†ï¼Œè®¡ç®—å½“å‰æ¨¡å‹å¯¹æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼
        for i in 0..train_set.shape()[0] {
            let features = tensor_slice!(train_set, i, 0..3).transpose();
            x.set_value(&features)?;

            // åœ¨æ¨¡å‹çš„predictèŠ‚ç‚¹ä¸Šæ‰§è¡Œå‰å‘ä¼ æ’­
            predict.forward()?;
            let predict_value = predict.value()?.unwrap();
            pred_vec.push(predict_value.get(&[0, 0]).get_data_number().unwrap());
        }

        // å°†1/0ç»“æœè½¬åŒ–æˆ1/-1ç»“æœï¼Œå¥½ä¸è®­ç»ƒæ ‡ç­¾çš„çº¦å®šä¸€è‡´
        let pred_tensor = Tensor::new(&pred_vec, &[pred_vec.len(), 1]) * 2.0 - 1.0;

        // è®¡ç®—å‡†ç¡®ç‡
        let train_set_labels = tensor_slice!(train_set, 0..train_set.shape()[0], 3);
        let pred_subset = tensor_slice!(pred_tensor, 0..pred_vec.len(), 0);

        let filtered_sum = tensor_where!(train_set_labels == pred_subset, 1.0, 0.0).sum();
        let accuracy = filtered_sum.get_data_number().unwrap() / train_set.shape()[0] as f32;
        let accuracy_percent = accuracy * 100.0;

        // æ‰“å°å½“å‰epochæ•°å’Œæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„æ­£ç¡®ç‡
        println!("è®­ç»ƒå›åˆ: {}, æ­£ç¡®ç‡: {:.1}%", epoch + 1, accuracy_percent);

        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡
        if accuracy >= target_accuracy {
            consecutive_success_count += 1;

            // æ£€æŸ¥æ˜¯å¦è¿ç»­è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡è¶³å¤Ÿæ¬¡æ•°
            if consecutive_success_count >= consecutive_success_required {
                test_passed = true;
                println!(
                    "ğŸ‰ æµ‹è¯•é€šè¿‡ï¼è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
                    consecutive_success_required,
                    target_accuracy * 100.0
                );
                break;
            }
        } else {
            consecutive_success_count = 0; // é‡ç½®è¿ç»­æˆåŠŸè®¡æ•°
        }
    }

    let duration = start_time.elapsed();
    println!("æ€»è€—æ—¶: {duration:.2?}");

    // æ£€æŸ¥æµ‹è¯•æ˜¯å¦é€šè¿‡
    if test_passed {
        println!("âœ… ä¼˜åŒ–å™¨ç¤ºä¾‹æµ‹è¯•æˆåŠŸé€šè¿‡ï¼");
        Ok(())
    } else {
        println!(
            "âŒ ä¼˜åŒ–å™¨ç¤ºä¾‹æµ‹è¯•å¤±è´¥ï¼šåœ¨{}ä¸ªepochå†…æœªèƒ½è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        );
        Err(GraphError::ComputationError(format!(
            "ä¼˜åŒ–å™¨ç¤ºä¾‹æµ‹è¯•å¤±è´¥ï¼šåœ¨{}ä¸ªepochå†…æœªèƒ½è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        )))
    }
}
