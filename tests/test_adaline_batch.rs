/*
 * @Author       : è€è‘£
 * @Date         : 2025-07-24 16:30:00
 * @LastEditors  : è€è‘£
 * @LastEditTime : 2025-12-21 16:30:00
 * @Description  : æ‰¹é‡ADALINEç¤ºä¾‹æµ‹è¯•ï¼Œå‚è€ƒè‡ªï¼šhttps://github.com/zc911/MatrixSlow/blob/master/example/ch03/adaline_batch.py
 */

use only_torch::nn::optimizer::{Adam, Optimizer};
use only_torch::nn::{Graph, GraphError};
use only_torch::tensor::Tensor;
use only_torch::{tensor_slice, tensor_where};

#[test]
fn test_adaline_batch_with_optimizer() -> Result<(), GraphError> {
    let start_time = std::time::Instant::now();

    // æ„é€ è®­ç»ƒæ•°æ®ï¼ˆä½¿ç”¨å›ºå®šç§å­ç¡®ä¿æµ‹è¯•å¯é‡å¤æ€§ï¼‰
    let seed_base: u64 = 42;
    let male_heights = Tensor::normal_seeded(171.0, 6.0, &[500], seed_base);
    let female_heights = Tensor::normal_seeded(158.0, 5.0, &[500], seed_base + 1);

    let male_weights = Tensor::normal_seeded(70.0, 10.0, &[500], seed_base + 2);
    let female_weights = Tensor::normal_seeded(57.0, 8.0, &[500], seed_base + 3);

    let male_bfrs = Tensor::normal_seeded(16.0, 2.0, &[500], seed_base + 4);
    let female_bfrs = Tensor::normal_seeded(22.0, 2.0, &[500], seed_base + 5);

    let male_labels = Tensor::new(&[1.0; 500], &[500]);
    let female_labels = Tensor::new(&[-1.0; 500], &[500]);

    let mut train_set = Tensor::stack(
        &[
            &Tensor::stack(&[&male_heights, &female_heights], false),
            &Tensor::stack(&[&male_weights, &female_weights], false),
            &Tensor::stack(&[&male_bfrs, &female_bfrs], false),
            &Tensor::stack(&[&male_labels, &female_labels], false),
        ],
        true,
    );
    train_set.permute_mut(&[1, 0]);
    train_set.shuffle_mut_seeded(Some(0), seed_base + 6); // ä½¿ç”¨å›ºå®šç§å­æ‰“ä¹±æ ·æœ¬é¡ºåº
    println!("è®­ç»ƒé›†å½¢çŠ¶: {:?}", train_set.shape());

    // æ‰¹å¤§å°
    let batch_size = 10;
    println!("æ‰¹å¤§å°: {batch_size}");

    // åˆ›å»ºè®¡ç®—å›¾
    let mut graph = Graph::new();

    // batch_size x 3çŸ©é˜µï¼Œæ¯è¡Œä¿å­˜ä¸€ä¸ªæ ·æœ¬ï¼Œæ•´ä¸ªèŠ‚ç‚¹ä¿å­˜ä¸€ä¸ªmini batchçš„æ ·æœ¬
    let x = graph.new_input_node(&[batch_size, 3], Some("X"))?;

    // ä¿å­˜ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„ç±»åˆ«æ ‡ç­¾
    let label = graph.new_input_node(&[batch_size, 1], Some("label"))?;

    // æƒå€¼å‘é‡ï¼Œ3x1çŸ©é˜µï¼ˆä½¿ç”¨å›ºå®šç§å­ï¼‰
    let w = graph.new_parameter_node_seeded(&[3, 1], Some("w"), seed_base + 7)?;

    // é˜ˆå€¼ï¼Œ1x1çŸ©é˜µï¼ˆä½¿ç”¨å›ºå®šç§å­ï¼‰
    let b = graph.new_parameter_node_seeded(&[1, 1], Some("b"), seed_base + 8)?;

    // å¯¹ä¸€ä¸ªmini batchçš„æ ·æœ¬è®¡ç®—è¾“å‡º
    let xw = graph.new_mat_mul_node(x, w, Some("xw"))?;

    // åˆ›å»ºå…¨1å‘é‡èŠ‚ç‚¹ï¼Œç”¨äºåç½®å¹¿æ’­
    let ones = graph.new_input_node(&[batch_size, 1], Some("ones"))?;

    // ä½¿ç”¨ScalarMultiplyèŠ‚ç‚¹å®ç°åç½®å¹¿æ’­ï¼šbias = b * ones
    let bias_broadcasted = graph.new_scalar_multiply_node(b, ones, Some("bias_broadcasted"))?;

    // è¾“å‡º = xw + bias_broadcasted
    let output = graph.new_add_node(&[xw, bias_broadcasted], Some("output"))?;
    let predict = graph.new_sign_node(output, None)?; // Sign ç›´æ¥è¾“å‡º {-1, 0, 1}

    // ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„æŸå¤±å‡½æ•°
    // ä½¿ç”¨MultiplyèŠ‚ç‚¹è®¡ç®—é€å…ƒç´ ä¹˜æ³•ï¼šlabel * output
    let label_output = graph.new_multiply_node(label, output, Some("label_output"))?;
    // PerceptionLoss å·²ç»è¾“å‡ºæ ‡é‡ [1,1]ï¼ˆå¯¹æ•´ä¸ª batch è‡ªåŠ¨å–å¹³å‡ï¼‰
    let loss = graph.new_perception_loss_node(label_output, Some("loss"))?;

    // å­¦ä¹ ç‡
    let learning_rate = 0.0001;

    // åˆ›å»ºAdamä¼˜åŒ–å™¨
    let mut optimizer = Adam::new_default(&graph, learning_rate)?;

    // æµ‹è¯•å‚æ•°
    let max_epochs = 100;
    let target_accuracy = 0.95; // 95%å‡†ç¡®ç‡ç›®æ ‡
    let consecutive_success_required = 3;
    let mut consecutive_success_count = 0;
    let mut test_passed = false;

    // è®¾ç½®å…¨1å‘é‡çš„å€¼ï¼ˆç”¨äºåç½®å¹¿æ’­ï¼‰
    let ones_data = vec![1.0; batch_size];
    let ones_tensor = Tensor::new(&ones_data, &[batch_size, 1]);
    graph.set_node_value(ones, Some(&ones_tensor))?;

    // è®­ç»ƒæ‰§è¡Œæœ€å¤šmax_epochsä¸ªepoch
    for epoch in 0..max_epochs {
        // éå†è®­ç»ƒé›†ä¸­çš„æ‰¹æ¬¡
        let num_batches = train_set.shape()[0].div_ceil(batch_size); // å‘ä¸Šå–æ•´

        for batch_idx in 0..num_batches {
            let start_idx = batch_idx * batch_size;
            let end_idx = std::cmp::min(start_idx + batch_size, train_set.shape()[0]);
            let actual_batch_size = end_idx - start_idx;

            // å¦‚æœæœ€åä¸€ä¸ªæ‰¹æ¬¡å¤§å°ä¸è¶³ï¼Œè·³è¿‡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            if actual_batch_size < batch_size {
                continue;
            }

            // å–ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„ç‰¹å¾ (batch_size x 3)
            let mut features_data = Vec::with_capacity(batch_size * 3);
            for i in start_idx..end_idx {
                for j in 0..3 {
                    features_data.push(train_set.get(&[i, j]).get_data_number().unwrap());
                }
            }
            let features = Tensor::new(&features_data, &[batch_size, 3]);

            // å–ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„æ ‡ç­¾ (batch_size x 1)
            let mut labels_data = Vec::with_capacity(batch_size);
            for i in start_idx..end_idx {
                labels_data.push(train_set.get(&[i, 3]).get_data_number().unwrap());
            }
            let labels = Tensor::new(&labels_data, &[batch_size, 1]);

            // å°†ç‰¹å¾èµ‹ç»™XèŠ‚ç‚¹ï¼Œå°†æ ‡ç­¾èµ‹ç»™labelèŠ‚ç‚¹
            graph.set_node_value(x, Some(&features))?;
            graph.set_node_value(label, Some(&labels))?;

            // ä½¿ç”¨æ–° API æ‰§è¡Œä¸€æ­¥è®­ç»ƒï¼ˆPyTorch é£æ ¼ï¼‰
            graph.zero_grad()?;
            graph.forward(loss)?;
            graph.backward(loss)?;
            optimizer.step(&mut graph)?;
        }

        // æ¯ä¸ªepochç»“æŸåè¯„ä»·æ¨¡å‹çš„æ­£ç¡®ç‡
        let mut pred_vec = Vec::new();

        // éå†è®­ç»ƒé›†ï¼Œè®¡ç®—å½“å‰æ¨¡å‹å¯¹æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼
        let num_batches = train_set.shape()[0].div_ceil(batch_size);

        for batch_idx in 0..num_batches {
            let start_idx = batch_idx * batch_size;
            let end_idx = std::cmp::min(start_idx + batch_size, train_set.shape()[0]);
            let actual_batch_size = end_idx - start_idx;

            // å¦‚æœæœ€åä¸€ä¸ªæ‰¹æ¬¡å¤§å°ä¸è¶³ï¼Œè·³è¿‡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            if actual_batch_size < batch_size {
                continue;
            }

            // å–ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„ç‰¹å¾
            let mut features_data = Vec::with_capacity(batch_size * 3);
            for i in start_idx..end_idx {
                for j in 0..3 {
                    features_data.push(train_set.get(&[i, j]).get_data_number().unwrap());
                }
            }
            let features = Tensor::new(&features_data, &[batch_size, 3]);
            graph.set_node_value(x, Some(&features))?;

            // å‰å‘ä¼ æ’­è®¡ç®—outputï¼ˆbias_broadcastedé€šè¿‡ScalarMultiplyèŠ‚ç‚¹è‡ªåŠ¨è®¡ç®—ï¼‰
            graph.forward(output)?;

            // åœ¨æ¨¡å‹çš„predictèŠ‚ç‚¹ä¸Šæ‰§è¡Œå‰å‘ä¼ æ’­
            graph.forward(predict)?;
            let predict_value = graph.get_node_value(predict)?.unwrap();

            // æ”¶é›†å½“å‰æ‰¹æ¬¡çš„é¢„æµ‹ç»“æœ
            for i in 0..batch_size {
                pred_vec.push(predict_value.get(&[i, 0]).get_data_number().unwrap());
            }
        }

        // Sign å·²ç›´æ¥è¾“å‡º {-1, 1}ï¼Œæ— éœ€è½¬æ¢
        let pred_tensor = Tensor::new(&pred_vec, &[pred_vec.len(), 1]);

        // è®¡ç®—å‡†ç¡®ç‡ï¼ˆåªè€ƒè™‘å®Œæ•´æ‰¹æ¬¡çš„æ ·æœ¬ï¼‰
        let valid_samples = (train_set.shape()[0] / batch_size) * batch_size;
        let train_set_labels = tensor_slice!(train_set, 0..valid_samples, 3);
        let pred_subset = tensor_slice!(pred_tensor, 0..valid_samples, 0);

        let filtered_sum = tensor_where!(train_set_labels == pred_subset, 1.0, 0.0).sum();
        let accuracy = filtered_sum.get_data_number().unwrap() / valid_samples as f32;
        let accuracy_percent = accuracy * 100.0;

        // æ‰“å°å½“å‰epochæ•°å’Œæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„æ­£ç¡®ç‡
        println!(
            "è®­ç»ƒå›åˆ: {}, æ­£ç¡®ç‡: {:.1}% (æœ‰æ•ˆæ ·æœ¬: {})",
            epoch + 1,
            accuracy_percent,
            valid_samples
        );

        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡
        if accuracy >= target_accuracy {
            consecutive_success_count += 1;

            // æ£€æŸ¥æ˜¯å¦è¿ç»­è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡è¶³å¤Ÿæ¬¡æ•°
            if consecutive_success_count >= consecutive_success_required {
                test_passed = true;
                println!(
                    "ğŸ‰ æµ‹è¯•é€šè¿‡ï¼è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
                    consecutive_success_required,
                    target_accuracy * 100.0
                );
                break;
            }
        } else {
            consecutive_success_count = 0; // é‡ç½®è¿ç»­æˆåŠŸè®¡æ•°
        }
    }

    let duration = start_time.elapsed();
    println!("æ€»è€—æ—¶: {duration:.2?}");

    // æ£€æŸ¥æµ‹è¯•æ˜¯å¦é€šè¿‡
    if test_passed {
        println!("âœ… æ‰¹é‡ADALINEä¼˜åŒ–å™¨æµ‹è¯•æˆåŠŸé€šè¿‡ï¼");
        Ok(())
    } else {
        println!(
            "âŒ æ‰¹é‡ADALINEä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥ï¼šåœ¨{}ä¸ªepochå†…æœªèƒ½è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        );
        Err(GraphError::ComputationError(format!(
            "æ‰¹é‡ADALINEä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥ï¼šåœ¨{}ä¸ªepochå†…æœªèƒ½è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        )))
    }
}
