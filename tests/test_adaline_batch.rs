/*
 * @Author       : è€è‘£
 * @Date         : 2025-07-24 16:30:00
 * @LastEditors  : è€è‘£
 * @LastEditTime : 2025-07-24 16:30:00
 * @Description  : æ‰¹é‡ADALINEç¤ºä¾‹æµ‹è¯•ï¼Œå‚è€ƒè‡ªï¼šhttps://github.com/zc911/MatrixSlow/blob/master/example/ch03/adaline_batch.py
 */

use only_torch::nn::optimizer::{Adam, Optimizer};
use only_torch::nn::{Graph, GraphError};
use only_torch::tensor::Tensor;
use only_torch::tensor_where;

#[test]
fn test_adaline_batch_with_optimizer() -> Result<(), GraphError> {
    let start_time = std::time::Instant::now();

    // æ„é€ è®­ç»ƒæ•°æ®ï¼ˆä¸Pythonç‰ˆæœ¬ç›¸åŒï¼‰
    let male_heights = Tensor::normal(171.0, 6.0, &[500]);
    let female_heights = Tensor::normal(158.0, 5.0, &[500]);

    let male_weights = Tensor::normal(70.0, 10.0, &[500]);
    let female_weights = Tensor::normal(57.0, 8.0, &[500]);

    let male_bfrs = Tensor::normal(16.0, 2.0, &[500]);
    let female_bfrs = Tensor::normal(22.0, 2.0, &[500]);

    let male_labels = Tensor::new(&[1.0; 500], &[500]);
    let female_labels = Tensor::new(&[-1.0; 500], &[500]);

    let mut train_set = Tensor::stack(
        &[
            &Tensor::stack(&[&male_heights, &female_heights], false),
            &Tensor::stack(&[&male_weights, &female_weights], false),
            &Tensor::stack(&[&male_bfrs, &female_bfrs], false),
            &Tensor::stack(&[&male_labels, &female_labels], false),
        ],
        true,
    );
    train_set.permute_mut(&[1, 0]);
    train_set.shuffle_mut(Some(0)); // éšæœºæ‰“ä¹±æ ·æœ¬é¡ºåº
    println!("è®­ç»ƒé›†å½¢çŠ¶: {:?}", train_set.shape());

    // æ‰¹å¤§å°
    let batch_size = 10;
    println!("æ‰¹å¤§å°: {batch_size}");

    // åˆ›å»ºè®¡ç®—å›¾
    let mut graph = Graph::new();

    // batch_size x 3çŸ©é˜µï¼Œæ¯è¡Œä¿å­˜ä¸€ä¸ªæ ·æœ¬ï¼Œæ•´ä¸ªèŠ‚ç‚¹ä¿å­˜ä¸€ä¸ªmini batchçš„æ ·æœ¬
    let x = graph.new_input_node(&[batch_size, 3], Some("X"))?;

    // ä¿å­˜ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„ç±»åˆ«æ ‡ç­¾
    let label = graph.new_input_node(&[batch_size, 1], Some("label"))?;

    // æƒå€¼å‘é‡ï¼Œ3x1çŸ©é˜µ
    let w = graph.new_parameter_node(&[3, 1], Some("w"))?;

    // é˜ˆå€¼ï¼Œ1x1çŸ©é˜µ
    let b = graph.new_parameter_node(&[1, 1], Some("b"))?;

    // å¯¹ä¸€ä¸ªmini batchçš„æ ·æœ¬è®¡ç®—è¾“å‡º
    let xw = graph.new_mat_mul_node(x, w, Some("xw"))?;

    // åˆ›å»ºåç½®å¹¿æ’­èŠ‚ç‚¹ï¼ˆæ‰‹åŠ¨è®¾ç½®å€¼ï¼‰
    let bias_broadcasted = graph.new_input_node(&[batch_size, 1], Some("bias_broadcasted"))?;

    // è¾“å‡º = xw + bias_broadcasted
    let output = graph.new_add_node(&[xw, bias_broadcasted], Some("output"))?;
    let predict = graph.new_step_node(output, None)?;

    // ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„æŸå¤±å‡½æ•°
    // ä½¿ç”¨é€å…ƒç´ ä¹˜æ³•ï¼šlabel * output
    let loss_input = graph.new_input_node(&[batch_size, 1], Some("loss_input"))?;
    let loss = graph.new_perception_loss_node(loss_input, Some("loss"))?;

    // å­¦ä¹ ç‡
    let learning_rate = 0.0001;

    // åˆ›å»ºAdamä¼˜åŒ–å™¨
    let mut optimizer = Adam::new_default(&graph, learning_rate)?;

    // æµ‹è¯•å‚æ•°
    let max_epochs = 50;
    let target_accuracy = 0.95; // 95%
    let consecutive_success_required = 3;
    let mut consecutive_success_count = 0;
    let mut test_passed = false;

    // è®¾ç½®å…¨1å‘é‡çš„å€¼ï¼ˆç”¨äºåç½®å¹¿æ’­ï¼‰
    let ones_data = vec![1.0; batch_size];
    let ones_tensor = Tensor::new(&ones_data, &[batch_size, 1]);

    // è®­ç»ƒæ‰§è¡Œæœ€å¤š50ä¸ªepochï¼Œæˆ–ç›´åˆ°è¾¾åˆ°æˆåŠŸæ¡ä»¶
    for epoch in 0..max_epochs {
        // éå†è®­ç»ƒé›†ä¸­çš„æ‰¹æ¬¡
        let num_batches = train_set.shape()[0].div_ceil(batch_size); // å‘ä¸Šå–æ•´

        for batch_idx in 0..num_batches {
            let start_idx = batch_idx * batch_size;
            let end_idx = std::cmp::min(start_idx + batch_size, train_set.shape()[0]);
            let actual_batch_size = end_idx - start_idx;

            // å¦‚æœæœ€åä¸€ä¸ªæ‰¹æ¬¡å¤§å°ä¸è¶³ï¼Œè·³è¿‡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            if actual_batch_size < batch_size {
                continue;
            }

            // å–ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„ç‰¹å¾ (batch_size x 3)
            let mut features_data = Vec::with_capacity(batch_size * 3);
            for i in start_idx..end_idx {
                for j in 0..3 {
                    features_data.push(train_set.get(&[i, j]).get_data_number().unwrap());
                }
            }
            let features = Tensor::new(&features_data, &[batch_size, 3]);

            // å–ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„æ ‡ç­¾ (batch_size x 1)
            let mut labels_data = Vec::with_capacity(batch_size);
            for i in start_idx..end_idx {
                labels_data.push(train_set.get(&[i, 3]).get_data_number().unwrap());
            }
            let labels = Tensor::new(&labels_data, &[batch_size, 1]);

            // å°†ç‰¹å¾èµ‹ç»™XèŠ‚ç‚¹ï¼Œå°†æ ‡ç­¾èµ‹ç»™labelèŠ‚ç‚¹
            graph.set_node_value(x, Some(&features))?;
            graph.set_node_value(label, Some(&labels))?;

            // æ‰‹åŠ¨è®¡ç®—åç½®å¹¿æ’­ï¼šb_broadcasted = ones * b
            let b_value = graph.get_node_value(b)?.unwrap();
            let b_broadcasted_value =
                &ones_tensor * b_value.get(&[0, 0]).get_data_number().unwrap();
            graph.set_node_value(bias_broadcasted, Some(&b_broadcasted_value))?;

            // å‰å‘ä¼ æ’­è®¡ç®—output = xw + bias_broadcasted
            graph.forward_node(output)?;

            // è®¡ç®—æŸå¤±è¾“å…¥ï¼šlabel * output (é€å…ƒç´ ä¹˜æ³•)
            let output_value = graph.get_node_value(output)?.unwrap();
            let loss_input_value = &labels * output_value;
            graph.set_node_value(loss_input, Some(&loss_input_value))?;

            // ä½¿ç”¨ä¼˜åŒ–å™¨æ‰§è¡Œä¸€æ­¥è®­ç»ƒ
            optimizer.one_step(&mut graph, loss)?;
        }

        // æ¯ä¸ªbatchç»“æŸåæ›´æ–°å‚æ•°
        optimizer.update(&mut graph)?;

        // æ¯ä¸ªepochç»“æŸåè¯„ä»·æ¨¡å‹çš„æ­£ç¡®ç‡
        let mut pred_vec = Vec::new();

        // éå†è®­ç»ƒé›†ï¼Œè®¡ç®—å½“å‰æ¨¡å‹å¯¹æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼
        let num_batches = train_set.shape()[0].div_ceil(batch_size);

        for batch_idx in 0..num_batches {
            let start_idx = batch_idx * batch_size;
            let end_idx = std::cmp::min(start_idx + batch_size, train_set.shape()[0]);
            let actual_batch_size = end_idx - start_idx;

            // å¦‚æœæœ€åä¸€ä¸ªæ‰¹æ¬¡å¤§å°ä¸è¶³ï¼Œè·³è¿‡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            if actual_batch_size < batch_size {
                continue;
            }

            // å–ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„ç‰¹å¾
            let mut features_data = Vec::with_capacity(batch_size * 3);
            for i in start_idx..end_idx {
                for j in 0..3 {
                    features_data.push(train_set.get(&[i, j]).get_data_number().unwrap());
                }
            }
            let features = Tensor::new(&features_data, &[batch_size, 3]);
            graph.set_node_value(x, Some(&features))?;

            // æ‰‹åŠ¨è®¡ç®—åç½®å¹¿æ’­
            let b_value = graph.get_node_value(b)?.unwrap();
            let b_broadcasted_value =
                &ones_tensor * b_value.get(&[0, 0]).get_data_number().unwrap();
            graph.set_node_value(bias_broadcasted, Some(&b_broadcasted_value))?;

            // å‰å‘ä¼ æ’­è®¡ç®—output
            graph.forward_node(output)?;

            // åœ¨æ¨¡å‹çš„predictèŠ‚ç‚¹ä¸Šæ‰§è¡Œå‰å‘ä¼ æ’­
            graph.forward_node(predict)?;
            let predict_value = graph.get_node_value(predict)?.unwrap();

            // æ”¶é›†å½“å‰æ‰¹æ¬¡çš„é¢„æµ‹ç»“æœ
            for i in 0..batch_size {
                pred_vec.push(predict_value.get(&[i, 0]).get_data_number().unwrap());
            }
        }

        // å°†1/0ç»“æœè½¬åŒ–æˆ1/-1ç»“æœï¼Œå¥½ä¸è®­ç»ƒæ ‡ç­¾çš„çº¦å®šä¸€è‡´
        let pred_tensor = Tensor::new(&pred_vec, &[pred_vec.len(), 1]) * 2.0 - 1.0;

        // è®¡ç®—å‡†ç¡®ç‡ï¼ˆåªè€ƒè™‘å®Œæ•´æ‰¹æ¬¡çš„æ ·æœ¬ï¼‰
        let valid_samples = (train_set.shape()[0] / batch_size) * batch_size;
        let train_set_labels = train_set.slice(&[&(0..valid_samples), &3]);
        let pred_subset = pred_tensor.slice(&[&(0..valid_samples), &0]);

        let filtered_sum = tensor_where!(train_set_labels == pred_subset, 1.0, 0.0).sum();
        let accuracy = filtered_sum.get_data_number().unwrap() / valid_samples as f32;
        let accuracy_percent = accuracy * 100.0;

        // æ‰“å°å½“å‰epochæ•°å’Œæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„æ­£ç¡®ç‡
        println!(
            "è®­ç»ƒå›åˆ: {}, æ­£ç¡®ç‡: {:.1}% (æœ‰æ•ˆæ ·æœ¬: {})",
            epoch + 1,
            accuracy_percent,
            valid_samples
        );

        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡
        if accuracy >= target_accuracy {
            consecutive_success_count += 1;

            // æ£€æŸ¥æ˜¯å¦è¿ç»­è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡è¶³å¤Ÿæ¬¡æ•°
            if consecutive_success_count >= consecutive_success_required {
                test_passed = true;
                println!(
                    "ğŸ‰ æµ‹è¯•é€šè¿‡ï¼è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
                    consecutive_success_required,
                    target_accuracy * 100.0
                );
                break;
            }
        } else {
            consecutive_success_count = 0; // é‡ç½®è¿ç»­æˆåŠŸè®¡æ•°
        }
    }

    let duration = start_time.elapsed();
    println!("æ€»è€—æ—¶: {duration:.2?}");

    // æ£€æŸ¥æµ‹è¯•æ˜¯å¦é€šè¿‡
    if test_passed {
        println!("âœ… æ‰¹é‡ADALINEä¼˜åŒ–å™¨æµ‹è¯•æˆåŠŸé€šè¿‡ï¼");
        Ok(())
    } else {
        println!(
            "âŒ æ‰¹é‡ADALINEä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥ï¼šåœ¨{}ä¸ªepochå†…æœªèƒ½è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        );
        Err(GraphError::ComputationError(format!(
            "æ‰¹é‡ADALINEä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥ï¼šåœ¨{}ä¸ªepochå†…æœªèƒ½è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        )))
    }
}
