/*
 * @Author       : è€è‘£
 * @Date         : 2025-07-24 16:30:00
 * @LastEditors  : è€è‘£
 * @LastEditTime : 2026-01-17 16:30:00
 * @Description  : æ‰¹é‡ ADALINE ç¤ºä¾‹æµ‹è¯•
 *
 * ADALINE (Adaptive Linear Neuron) æ˜¯ä¸€ä¸ªç®€å•çš„çº¿æ€§åˆ†ç±»å™¨ï¼š
 *   output = sign(x @ w + b)
 *
 * æœ¬æµ‹è¯•å±•ç¤º PyTorch é£æ ¼çš„é«˜å±‚ API ä½¿ç”¨æ–¹å¼ï¼š
 * - ä½¿ç”¨ Linear å±‚å°è£…æƒé‡å’Œåç½®
 * - ä½¿ç”¨ Module trait è·å–å‚æ•°
 * - æ— éœ€æ‰‹åŠ¨å¤„ç† bias å¹¿æ’­
 *
 * å‚è€ƒè‡ªï¼šhttps://github.com/zc911/MatrixSlow/blob/master/example/ch03/adaline_batch.py
 */

use only_torch::nn::layer::Linear;
use only_torch::nn::optimizer::{Adam, Optimizer};
use only_torch::nn::{Graph, GraphError, Module, VarActivationOps, VarLossOps};
use only_torch::tensor::Tensor;
use only_torch::{tensor_slice, tensor_where};

#[test]
fn test_adaline_batch_with_optimizer() -> Result<(), GraphError> {
    let start_time = std::time::Instant::now();

    // ==================== æ•°æ®å‡†å¤‡ ====================
    // æ„é€ è®­ç»ƒæ•°æ®ï¼ˆä½¿ç”¨å›ºå®šç§å­ç¡®ä¿æµ‹è¯•å¯é‡å¤æ€§ï¼‰
    let seed_base: u64 = 42;
    let male_heights = Tensor::normal_seeded(171.0, 6.0, &[500], seed_base);
    let female_heights = Tensor::normal_seeded(158.0, 5.0, &[500], seed_base + 1);

    let male_weights = Tensor::normal_seeded(70.0, 10.0, &[500], seed_base + 2);
    let female_weights = Tensor::normal_seeded(57.0, 8.0, &[500], seed_base + 3);

    let male_bfrs = Tensor::normal_seeded(16.0, 2.0, &[500], seed_base + 4);
    let female_bfrs = Tensor::normal_seeded(22.0, 2.0, &[500], seed_base + 5);

    let male_labels = Tensor::new(&[1.0; 500], &[500]);
    let female_labels = Tensor::new(&[-1.0; 500], &[500]);

    let mut train_set = Tensor::stack(
        &[
            &Tensor::stack(&[&male_heights, &female_heights], false),
            &Tensor::stack(&[&male_weights, &female_weights], false),
            &Tensor::stack(&[&male_bfrs, &female_bfrs], false),
            &Tensor::stack(&[&male_labels, &female_labels], false),
        ],
        true,
    );
    train_set.permute_mut(&[1, 0]);
    train_set.shuffle_mut_seeded(Some(0), seed_base + 6);
    println!("è®­ç»ƒé›†å½¢çŠ¶: {:?}", train_set.shape());

    // ==================== æ¨¡å‹å®šä¹‰ ====================
    let batch_size = 10;
    println!("æ‰¹å¤§å°: {batch_size}");

    // åˆ›å»ºè®¡ç®—å›¾
    let graph = Graph::new();

    // è¾“å…¥å ä½ç¬¦ï¼š[batch_size, 3] ç‰¹å¾ï¼ˆèº«é«˜ã€ä½“é‡ã€ä½“è„‚ç‡ï¼‰
    let x = graph.zeros(&[batch_size, 3])?;

    // æ ‡ç­¾å ä½ç¬¦ï¼š[batch_size, 1]
    let label = graph.zeros(&[batch_size, 1])?;

    // ADALINE æ¨¡å‹ï¼šå•å±‚ Linear (3 -> 1)
    // Linear å±‚å†…éƒ¨è‡ªåŠ¨å¤„ç† bias å¹¿æ’­ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ
    let fc = Linear::new_seeded(&graph, 3, 1, true, "fc", seed_base + 7)?;

    // å‰å‘ä¼ æ’­ï¼šoutput = x @ w + b
    let output = fc.forward(&x);

    // é¢„æµ‹ï¼šsign(output) è¾“å‡º {-1, 0, 1}
    let predict = output.sign();

    // ==================== æŸå¤±å‡½æ•° ====================
    // Perception Loss: max(0, -label * output)
    let label_output = &label * &output;
    let loss = label_output.perception_loss();

    // ==================== ä¼˜åŒ–å™¨ ====================
    let learning_rate = 0.001;

    // ä½¿ç”¨ Module trait è·å–å‚æ•°ï¼ˆæ¨èæ–¹å¼ï¼‰
    let params = fc.parameters();
    let mut optimizer = Adam::new(&graph, &params, learning_rate);

    // æµ‹è¯•å‚æ•°
    let max_epochs = 100;
    let target_accuracy = 0.95; // 95%å‡†ç¡®ç‡ç›®æ ‡
    let consecutive_success_required = 3;
    let mut consecutive_success_count = 0;
    let mut test_passed = false;

    // è®­ç»ƒæ‰§è¡Œæœ€å¤šmax_epochsä¸ªepoch
    for epoch in 0..max_epochs {
        // éå†è®­ç»ƒé›†ä¸­çš„æ‰¹æ¬¡
        let num_batches = train_set.shape()[0].div_ceil(batch_size); // å‘ä¸Šå–æ•´

        for batch_idx in 0..num_batches {
            let start_idx = batch_idx * batch_size;
            let end_idx = std::cmp::min(start_idx + batch_size, train_set.shape()[0]);
            let actual_batch_size = end_idx - start_idx;

            // å¦‚æœæœ€åä¸€ä¸ªæ‰¹æ¬¡å¤§å°ä¸è¶³ï¼Œè·³è¿‡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            if actual_batch_size < batch_size {
                continue;
            }

            // å–ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„ç‰¹å¾ (batch_size x 3)
            let mut features_data = Vec::with_capacity(batch_size * 3);
            for i in start_idx..end_idx {
                for j in 0..3 {
                    features_data.push(train_set.get(&[i, j]).get_data_number().unwrap());
                }
            }
            let features = Tensor::new(&features_data, &[batch_size, 3]);

            // å–ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„æ ‡ç­¾ (batch_size x 1)
            let mut labels_data = Vec::with_capacity(batch_size);
            for i in start_idx..end_idx {
                labels_data.push(train_set.get(&[i, 3]).get_data_number().unwrap());
            }
            let labels = Tensor::new(&labels_data, &[batch_size, 1]);

            // å°†ç‰¹å¾èµ‹ç»™XèŠ‚ç‚¹ï¼Œå°†æ ‡ç­¾èµ‹ç»™labelèŠ‚ç‚¹
            x.set_value(&features)?;
            label.set_value(&labels)?;

            // ä½¿ç”¨ minimize ä¸€æ­¥å®Œæˆè®­ç»ƒ
            optimizer.minimize(&loss)?;
        }

        // æ¯ä¸ªepochç»“æŸåè¯„ä»·æ¨¡å‹çš„æ­£ç¡®ç‡
        let mut pred_vec = Vec::new();

        // éå†è®­ç»ƒé›†ï¼Œè®¡ç®—å½“å‰æ¨¡å‹å¯¹æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼
        let num_batches = train_set.shape()[0].div_ceil(batch_size);

        for batch_idx in 0..num_batches {
            let start_idx = batch_idx * batch_size;
            let end_idx = std::cmp::min(start_idx + batch_size, train_set.shape()[0]);
            let actual_batch_size = end_idx - start_idx;

            // å¦‚æœæœ€åä¸€ä¸ªæ‰¹æ¬¡å¤§å°ä¸è¶³ï¼Œè·³è¿‡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            if actual_batch_size < batch_size {
                continue;
            }

            // å–ä¸€ä¸ªmini batchçš„æ ·æœ¬çš„ç‰¹å¾
            let mut features_data = Vec::with_capacity(batch_size * 3);
            for i in start_idx..end_idx {
                for j in 0..3 {
                    features_data.push(train_set.get(&[i, j]).get_data_number().unwrap());
                }
            }
            let features = Tensor::new(&features_data, &[batch_size, 3]);
            x.set_value(&features)?;

            // åœ¨æ¨¡å‹çš„predictèŠ‚ç‚¹ä¸Šæ‰§è¡Œå‰å‘ä¼ æ’­
            predict.forward()?;
            let predict_value = predict.value()?.unwrap();

            // æ”¶é›†å½“å‰æ‰¹æ¬¡çš„é¢„æµ‹ç»“æœ
            for i in 0..batch_size {
                pred_vec.push(predict_value.get(&[i, 0]).get_data_number().unwrap());
            }
        }

        // Sign å·²ç›´æ¥è¾“å‡º {-1, 1}ï¼Œæ— éœ€è½¬æ¢
        let pred_tensor = Tensor::new(&pred_vec, &[pred_vec.len(), 1]);

        // è®¡ç®—å‡†ç¡®ç‡ï¼ˆåªè€ƒè™‘å®Œæ•´æ‰¹æ¬¡çš„æ ·æœ¬ï¼‰
        let valid_samples = (train_set.shape()[0] / batch_size) * batch_size;
        let train_set_labels = tensor_slice!(train_set, 0..valid_samples, 3);
        let pred_subset = tensor_slice!(pred_tensor, 0..valid_samples, 0);

        let filtered_sum = tensor_where!(train_set_labels == pred_subset, 1.0, 0.0).sum();
        let accuracy = filtered_sum.get_data_number().unwrap() / valid_samples as f32;
        let accuracy_percent = accuracy * 100.0;

        // æ‰“å°å½“å‰epochæ•°å’Œæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„æ­£ç¡®ç‡
        println!(
            "è®­ç»ƒå›åˆ: {}, æ­£ç¡®ç‡: {:.1}% (æœ‰æ•ˆæ ·æœ¬: {})",
            epoch + 1,
            accuracy_percent,
            valid_samples
        );

        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡
        if accuracy >= target_accuracy {
            consecutive_success_count += 1;

            // æ£€æŸ¥æ˜¯å¦è¿ç»­è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡è¶³å¤Ÿæ¬¡æ•°
            if consecutive_success_count >= consecutive_success_required {
                test_passed = true;
                println!(
                    "ğŸ‰ æµ‹è¯•é€šè¿‡ï¼è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
                    consecutive_success_required,
                    target_accuracy * 100.0
                );
                break;
            }
        } else {
            consecutive_success_count = 0; // é‡ç½®è¿ç»­æˆåŠŸè®¡æ•°
        }
    }

    let duration = start_time.elapsed();
    println!("æ€»è€—æ—¶: {duration:.2?}");

    // æ£€æŸ¥æµ‹è¯•æ˜¯å¦é€šè¿‡
    if test_passed {
        println!("âœ… æ‰¹é‡ADALINEä¼˜åŒ–å™¨æµ‹è¯•æˆåŠŸé€šè¿‡ï¼");
        Ok(())
    } else {
        println!(
            "âŒ æ‰¹é‡ADALINEä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥ï¼šåœ¨{}ä¸ªepochå†…æœªèƒ½è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        );
        Err(GraphError::ComputationError(format!(
            "æ‰¹é‡ADALINEä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥ï¼šåœ¨{}ä¸ªepochå†…æœªèƒ½è¿ç»­{}æ¬¡è¾¾åˆ°{:.1}%ä»¥ä¸Šå‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        )))
    }
}
