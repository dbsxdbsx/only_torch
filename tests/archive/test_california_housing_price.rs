/*
 * @Author       : è€è‘£
 * @Date         : 2025-12-22
 * @LastEditTime : 2026-01-17
 * @Description  : California Housing æˆ¿ä»·å›å½’é›†æˆæµ‹è¯•
 *
 * ä½¿ç”¨çœŸå®æ•°æ®é›†éªŒè¯ MSELoss + MLP å›å½’ä»»åŠ¡
 * å±•ç¤º PyTorch é£æ ¼çš„é«˜å±‚ APIï¼šLinear å±‚ + Module trait
 */

use approx::assert_abs_diff_eq;
use only_torch::data::CaliforniaHousingDataset;
use only_torch::nn::layer::Linear;
use only_torch::nn::optimizer::{Adam, Optimizer};
use only_torch::nn::{Graph, GraphError, Module, VarActivationOps, VarLossOps};
use only_torch::tensor::Tensor;
use std::fs;
use std::time::Instant;

/// California Housing æˆ¿ä»·å›å½’ï¼ˆPyTorch é£æ ¼ APIï¼‰
///
/// ç½‘ç»œç»“æ„ï¼šInput(8) â†’ Linear(128, Softplus) â†’ Linear(64, Softplus) â†’ Linear(32, Softplus) â†’ Linear(1)
/// ç›®æ ‡ï¼šRÂ² â‰¥ 0.70 (70%)
#[test]
fn test_california_housing_regression() -> Result<(), GraphError> {
    let start_time = Instant::now();

    println!("\n{}", "=".repeat(60));
    println!("=== California Housing æˆ¿ä»·å›å½’æµ‹è¯• ===");
    println!("{}\n", "=".repeat(60));

    // ========== 1. åŠ è½½æ•°æ® ==========
    println!("[1/4] åŠ è½½ California Housing æ•°æ®é›†...");
    let load_start = Instant::now();

    let dataset = CaliforniaHousingDataset::load_default()
        .expect("åŠ è½½ California Housing æ•°æ®é›†å¤±è´¥")
        .standardize();

    let (train_data, test_data) = dataset
        .train_test_split(0.2, Some(42))
        .expect("åˆ’åˆ†æ•°æ®é›†å¤±è´¥");

    println!(
        "  âœ“ è®­ç»ƒé›†: {} æ ·æœ¬ï¼Œæµ‹è¯•é›†: {} æ ·æœ¬ï¼Œè€—æ—¶ {:.2}s",
        train_data.len(),
        test_data.len(),
        load_start.elapsed().as_secs_f32()
    );

    // ========== 2. è®­ç»ƒé…ç½® ==========
    let batch_size = 256;
    let train_samples = 16000;
    let test_samples = 1024;
    let max_epochs = 30;
    let num_batches = train_samples / batch_size;
    let learning_rate = 0.01;
    let target_r2 = 0.70;

    println!("\n[2/4] è®­ç»ƒé…ç½®ï¼š");
    println!("  - Batch Size: {batch_size}");
    println!("  - è®­ç»ƒæ ·æœ¬: {train_samples} (å…± {num_batches} ä¸ª batch)");
    println!("  - æµ‹è¯•æ ·æœ¬: {test_samples}");
    println!("  - æœ€å¤§ Epochs: {max_epochs}");
    println!("  - å­¦ä¹ ç‡: {learning_rate}");
    println!("  - ç›®æ ‡ RÂ²: {:.0}%", target_r2 * 100.0);

    // ========== 3. æ„å»ºç½‘ç»œï¼ˆä½¿ç”¨ Linear å±‚ï¼‰==========
    println!("\n[3/4] æ„å»º MLP: 8 -> 128 -> 64 -> 32 -> 1...");

    let graph = Graph::new_with_seed(42);

    // è¾“å…¥/æ ‡ç­¾å ä½ç¬¦
    let x = graph.zeros(&[batch_size, 8])?;
    let y_true = graph.zeros(&[batch_size, 1])?;

    // ä½¿ç”¨ Linear å±‚æ„å»ºç½‘ç»œï¼ˆPyTorch é£æ ¼ï¼‰
    let fc1 = Linear::new_seeded(&graph, 8, 128, true, "fc1", 100)?;
    let fc2 = Linear::new_seeded(&graph, 128, 64, true, "fc2", 200)?;
    let fc3 = Linear::new_seeded(&graph, 64, 32, true, "fc3", 300)?;
    let fc4 = Linear::new_seeded(&graph, 32, 1, true, "fc4", 400)?;

    // Xavier åˆå§‹åŒ–ï¼ˆé€‚åˆ Softplus æ¿€æ´»ï¼‰
    let xavier_init = |fan_in: usize, fan_out: usize, seed: u64| -> Tensor {
        let std = (2.0 / (fan_in + fan_out) as f32).sqrt();
        Tensor::normal_seeded(0.0, std, &[fan_in, fan_out], seed)
    };
    fc1.weights().set_value(&xavier_init(8, 128, 42))?;
    fc2.weights().set_value(&xavier_init(128, 64, 43))?;
    fc3.weights().set_value(&xavier_init(64, 32, 44))?;
    fc4.weights().set_value(&xavier_init(32, 1, 45))?;

    // å‰å‘ä¼ æ’­é“¾
    let a1 = fc1.forward(&x).softplus();
    let a2 = fc2.forward(&a1).softplus();
    let a3 = fc3.forward(&a2).softplus();
    let y_pred = fc4.forward(&a3);

    // æŸå¤±å‡½æ•°
    let loss = y_pred.mse_loss(&y_true)?;

    println!("  âœ“ ç½‘ç»œæ„å»ºå®Œæˆï¼š8 -> 128 -> 64 -> 32 -> 1ï¼ˆ4 å±‚ MLPï¼‰");

    // æ”¶é›†æ‰€æœ‰å‚æ•°ï¼ˆä½¿ç”¨ Module traitï¼‰
    let mut params: Vec<_> = fc1.parameters();
    params.extend(fc2.parameters());
    params.extend(fc3.parameters());
    params.extend(fc4.parameters());
    println!("  âœ“ å‚æ•°èŠ‚ç‚¹ï¼š{} ä¸ª Var", params.len());

    // ä¿å­˜ç½‘ç»œç»“æ„å¯è§†åŒ–
    let output_dir = "tests/outputs";
    fs::create_dir_all(output_dir).ok();
    graph
        .inner()
        .save_visualization(format!("{output_dir}/california_housing"), None)?;
    graph
        .inner()
        .save_summary(format!("{output_dir}/california_housing_summary.md"))?;
    println!("  âœ“ ç½‘ç»œç»“æ„å·²ä¿å­˜: {output_dir}/california_housing.png");

    // ========== 4. è®­ç»ƒå¾ªç¯ ==========
    println!("\n[4/4] å¼€å§‹è®­ç»ƒ...\n");

    let mut optimizer = Adam::new(&graph, &params, learning_rate);

    // é¢„å…ˆæ„å»º batch æ•°æ®
    let train_batches = build_batches(&train_data, batch_size, num_batches);
    let test_batches_data = build_batches(&test_data, batch_size, test_samples / batch_size);

    let mut best_r2 = f32::NEG_INFINITY;

    for epoch in 0..max_epochs {
        let epoch_start = Instant::now();
        let mut epoch_loss_sum = 0.0;

        // è®­ç»ƒ
        for (batch_x, batch_y) in &train_batches {
            x.set_value(batch_x)?;
            y_true.set_value(batch_y)?;

            let loss_val = optimizer.minimize(&loss)?;
            epoch_loss_sum += loss_val;
        }

        let epoch_avg_loss = epoch_loss_sum / num_batches as f32;

        // æµ‹è¯•é›†è¯„ä¼°ï¼ˆè®¡ç®— RÂ²ï¼‰
        graph.eval();
        let mut predictions: Vec<f32> = Vec::with_capacity(test_samples);
        let mut actuals: Vec<f32> = Vec::with_capacity(test_samples);

        for (batch_x, batch_y) in &test_batches_data {
            x.set_value(batch_x)?;
            y_true.set_value(batch_y)?;

            y_pred.forward()?;

            let pred_tensor = y_pred.value()?.unwrap();
            for i in 0..batch_size {
                predictions.push(pred_tensor[[i, 0]]);
                actuals.push(batch_y[[i, 0]]);
            }
        }

        graph.train();

        // è®¡ç®— RÂ²
        let r2_score = compute_r2(&predictions, &actuals);
        best_r2 = best_r2.max(r2_score);

        println!(
            "Epoch {:2}/{}: loss = {:.4}, RÂ² = {:.2}% ({:.4}), è€—æ—¶ {:.2}s",
            epoch + 1,
            max_epochs,
            epoch_avg_loss,
            r2_score * 100.0,
            r2_score,
            epoch_start.elapsed().as_secs_f32()
        );

        // æå‰ç»“æŸæ¡ä»¶
        if r2_score >= target_r2 {
            println!("\nğŸ‰ è¾¾åˆ°ç›®æ ‡ RÂ² â‰¥ {:.0}%ï¼", target_r2 * 100.0);
            break;
        }
    }

    let total_duration = start_time.elapsed();
    println!("\næ€»è€—æ—¶: {:.2}s", total_duration.as_secs_f32());

    // æ‰“å°æ¨¡å‹æ‘˜è¦
    println!("\næ¨¡å‹æ‘˜è¦ï¼š");
    graph.inner().summary();

    // æœ€ç»ˆéªŒè¯
    println!("\n{}", "=".repeat(60));
    println!("ç»“æœéªŒè¯:");
    println!("  æœ€ä½³ RÂ²: {:.4} ({:.1}%)", best_r2, best_r2 * 100.0);

    assert!(
        best_r2 >= target_r2,
        "RÂ² åˆ†æ•°åº” â‰¥ {:.0}%ï¼Œå®é™…: {:.2}%",
        target_r2 * 100.0,
        best_r2 * 100.0
    );

    println!("\nâœ… California Housing å›å½’æµ‹è¯•é€šè¿‡ï¼");
    println!("   æ¨¡å‹è§£é‡Šäº† {:.1}% çš„ç›®æ ‡å˜é‡æ–¹å·®", best_r2 * 100.0);
    println!("{}\n", "=".repeat(60));

    if best_r2 >= 0.85 {
        println!("   ğŸ‰ è¾¾åˆ°ä¼˜ç§€æ°´å¹³ (RÂ² â‰¥ 85%)ï¼");
    }

    Ok(())
}

/// æ„å»º batch æ•°æ®
fn build_batches(
    data: &CaliforniaHousingDataset,
    batch_size: usize,
    num_batches: usize,
) -> Vec<(Tensor, Tensor)> {
    let mut batches = Vec::with_capacity(num_batches);

    for batch_idx in 0..num_batches {
        let mut x_data = Vec::with_capacity(batch_size * 8);
        let mut y_data = Vec::with_capacity(batch_size);

        for i in 0..batch_size {
            let idx = batch_idx * batch_size + i;
            if idx < data.len() {
                let (features, target) = data.get(idx).unwrap();
                x_data.extend(features.flatten_view().iter().copied());
                y_data.push(target[[0]]);
            }
        }

        let x_tensor = Tensor::new(&x_data, &[batch_size, 8]);
        let y_tensor = Tensor::new(&y_data, &[batch_size, 1]);
        batches.push((x_tensor, y_tensor));
    }

    batches
}

/// è®¡ç®— RÂ² åˆ†æ•°
fn compute_r2(predictions: &[f32], actuals: &[f32]) -> f32 {
    let mean_actual: f32 = actuals.iter().sum::<f32>() / actuals.len() as f32;

    let ss_res: f32 = predictions
        .iter()
        .zip(actuals.iter())
        .map(|(pred, actual)| (actual - pred).powi(2))
        .sum();

    let ss_tot: f32 = actuals
        .iter()
        .map(|actual| (actual - mean_actual).powi(2))
        .sum();

    1.0 - (ss_res / ss_tot)
}

/// ç®€å•éªŒè¯æ•°æ®é›†åŠ è½½
#[test]
fn test_california_housing_data_loading() {
    let dataset = CaliforniaHousingDataset::load_default().expect("åŠ è½½æ•°æ®é›†å¤±è´¥");

    // éªŒè¯æ•°æ®é›†å¤§å°
    assert!(
        dataset.len() > 20000,
        "æ•°æ®é›†åº”æœ‰ 20000+ æ ·æœ¬ï¼Œå®é™…: {}",
        dataset.len()
    );

    // éªŒè¯ç‰¹å¾ç»´åº¦
    assert_eq!(dataset.feature_dim(), 8);

    // éªŒè¯å¯ä»¥è·å–å•ä¸ªæ ·æœ¬
    let (features, target) = dataset.get(0).expect("è·å–æ ·æœ¬å¤±è´¥");
    assert_eq!(features.shape(), &[8]);
    assert_eq!(target.shape(), &[1]);

    // éªŒè¯æ ‡å‡†åŒ–
    let standardized = dataset.standardize();
    assert!(standardized.is_standardized());

    println!("âœ… æ•°æ®åŠ è½½æµ‹è¯•é€šè¿‡ï¼");
}

/// éªŒè¯è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†
#[test]
fn test_california_housing_train_test_split() {
    let dataset = CaliforniaHousingDataset::load_default()
        .expect("åŠ è½½æ•°æ®é›†å¤±è´¥")
        .standardize();

    let total_len = dataset.len();
    let (train, test) = dataset.train_test_split(0.2, Some(42)).expect("åˆ’åˆ†å¤±è´¥");

    // éªŒè¯åˆ’åˆ†æ¯”ä¾‹
    let expected_test_size = (total_len as f32 * 0.2).round() as usize;
    assert_eq!(test.len(), expected_test_size);
    assert_eq!(train.len(), total_len - expected_test_size);

    // éªŒè¯åˆ’åˆ†ç¡®å®šæ€§
    let dataset2 = CaliforniaHousingDataset::load_default()
        .unwrap()
        .standardize();
    let (train2, _) = dataset2.train_test_split(0.2, Some(42)).unwrap();

    // ç›¸åŒç§å­åº”å¾—åˆ°ç›¸åŒçš„è®­ç»ƒé›†ç¬¬ä¸€ä¸ªæ ·æœ¬
    let (f1, t1) = train.get(0).unwrap();
    let (f2, t2) = train2.get(0).unwrap();

    assert_abs_diff_eq!(f1[[0]], f2[[0]], epsilon = 1e-6);
    assert_abs_diff_eq!(t1[[0]], t2[[0]], epsilon = 1e-6);

    println!("âœ… è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†æµ‹è¯•é€šè¿‡ï¼");
}
