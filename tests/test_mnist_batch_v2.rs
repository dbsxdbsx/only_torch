/*
 * @Author       : è€è‘£
 * @Date         : 2026-01-17
 * @Description  : MNIST Batch V2 é›†æˆæµ‹è¯•ï¼ˆä½¿ç”¨ V2 APIï¼‰
 *
 * å¯¹åº”åŸ test_mnist_batch.rsï¼Œæ”¹ç”¨ V2 APIï¼š
 * - Graph + Varï¼ˆä¸å†ç”¨ Graph + NodeIdï¼‰
 * - Optimizerï¼ˆPyTorch é£æ ¼ APIï¼‰
 * - æ‰‹åŠ¨æ„å»ºç½‘ç»œï¼ˆä¸ä½¿ç”¨ Linear å±‚ï¼ŒéªŒè¯åº•å±‚ matmul/add é“¾å¼è°ƒç”¨ï¼‰
 */

use only_torch::data::MnistDataset;
use only_torch::nn::{
    Adam, GraphError, Graph, Init, Optimizer, VarActivationOps, VarLossOps, VarMatrixOps,
};
use only_torch::tensor::Tensor;
use only_torch::tensor_slice;
use std::time::Instant;

/// MNIST Batch V2 é›†æˆæµ‹è¯•
///
/// æ‰‹åŠ¨æ„å»º MLPï¼ˆä¸ä½¿ç”¨ Linear å±‚ï¼‰ï¼ŒéªŒè¯ V2 API çš„åº•å±‚é“¾å¼è°ƒç”¨
#[test]
fn test_mnist_batch_v2() -> Result<(), GraphError> {
    let start_time = Instant::now();

    println!("\n{}", "=".repeat(60));
    println!("=== MNIST Batch V2 é›†æˆæµ‹è¯•ï¼ˆä½¿ç”¨ V2 APIï¼‰===");
    println!("{}\n", "=".repeat(60));

    // ========== 1. åŠ è½½æ•°æ® ==========
    println!("[1/4] åŠ è½½ MNIST æ•°æ®é›†...");
    let load_start = Instant::now();

    let train_data = MnistDataset::train()
        .expect("åŠ è½½ MNIST è®­ç»ƒé›†å¤±è´¥")
        .flatten();
    let test_data = MnistDataset::test()
        .expect("åŠ è½½ MNIST æµ‹è¯•é›†å¤±è´¥")
        .flatten();

    println!(
        "  âœ“ è®­ç»ƒé›†: {} æ ·æœ¬ï¼Œæµ‹è¯•é›†: {} æ ·æœ¬ï¼Œè€—æ—¶ {:.2}s",
        train_data.len(),
        test_data.len(),
        load_start.elapsed().as_secs_f32()
    );

    // ========== 2. è®­ç»ƒé…ç½® ==========
    let batch_size = 512;
    let train_samples = 5000;
    let test_samples = 1000;
    let max_epochs = 15;
    let num_batches = train_samples / batch_size;
    let learning_rate = 0.008;
    let target_accuracy = 0.90;
    let consecutive_success_required = 2;

    println!("\n[2/4] è®­ç»ƒé…ç½®ï¼š");
    println!("  - Batch Size: {batch_size}");
    println!("  - è®­ç»ƒæ ·æœ¬: {train_samples} (å…± {num_batches} ä¸ª batch)");
    println!("  - æµ‹è¯•æ ·æœ¬: {test_samples}");
    println!("  - æœ€å¤§ Epochs: {max_epochs}");
    println!("  - å­¦ä¹ ç‡: {learning_rate}");
    println!("  - ç›®æ ‡å‡†ç¡®ç‡: {:.0}%", target_accuracy * 100.0);

    // ========== 3. æ„å»ºç½‘ç»œï¼ˆæ‰‹åŠ¨ï¼Œä¸ä½¿ç”¨ Linear å±‚ï¼‰==========
    println!("\n[3/4] ä½¿ç”¨ V2 API æ‰‹åŠ¨æ„å»º MLP: 784 -> 128 (Sigmoid) -> 10...");

    let graph = Graph::new_with_seed(42);

    // è¾“å…¥å˜é‡ï¼ˆä½¿ç”¨ zeros å ä½ï¼‰
    let x = graph.zeros(&[batch_size, 784])?;
    let y = graph.zeros(&[batch_size, 10])?;

    // ç”¨äº bias å¹¿æ’­çš„ ones çŸ©é˜µ
    let ones = graph.input(&Tensor::ones(&[batch_size, 1]))?;

    // ========== æ‰‹åŠ¨æ„å»ºç½‘ç»œï¼ˆéªŒè¯ Var é“¾å¼è°ƒç”¨ï¼‰==========
    // éšè—å±‚å‚æ•°
    let w1 = graph.parameter(&[784, 128], Init::Kaiming, "w1")?;
    let b1 = graph.parameter(&[1, 128], Init::Zeros, "b1")?;

    // è¾“å‡ºå±‚å‚æ•°
    let w2 = graph.parameter(&[128, 10], Init::Kaiming, "w2")?;
    let b2 = graph.parameter(&[1, 10], Init::Zeros, "b2")?;

    // éšè—å±‚ï¼šz1 = x @ w1 + ones @ b1, a1 = sigmoid(z1)
    let z1 = x.matmul(&w1)?;
    let b1_broadcast = ones.matmul(&b1)?;
    let h1 = &z1 + &b1_broadcast;
    let a1 = h1.sigmoid();

    // è¾“å‡ºå±‚ï¼šz2 = a1 @ w2 + ones @ b2
    let z2 = a1.matmul(&w2)?;
    let b2_broadcast = ones.matmul(&b2)?;
    let logits = &z2 + &b2_broadcast;

    // æŸå¤±å‡½æ•°ï¼šcross_entropy å†…å« softmax
    let loss = logits.cross_entropy(&y)?;

    println!("  âœ“ ç½‘ç»œæ„å»ºå®Œæˆï¼ˆæ‰‹åŠ¨ matmul + bias å¹¿æ’­ï¼‰");
    println!("  âœ“ å‚æ•°ï¼šw1, b1, w2, b2");

    // æ”¶é›†æ‰€æœ‰å‚æ•°
    let all_params = vec![w1.clone(), b1.clone(), w2.clone(), b2.clone()];

    // ========== 4. åˆ›å»º V2 ä¼˜åŒ–å™¨ ==========
    let mut optimizer = Adam::new(&graph, &all_params, learning_rate);
    println!("  âœ“ ä¼˜åŒ–å™¨ï¼šAdam (lr={learning_rate})");

    // ========== 5. è®­ç»ƒå¾ªç¯ ==========
    println!("\n[4/4] å¼€å§‹è®­ç»ƒ...\n");

    let all_train_images = train_data.images();
    let all_train_labels = train_data.labels();
    let all_test_images = test_data.images();
    let all_test_labels = test_data.labels();

    let mut consecutive_success_count = 0;
    let mut test_passed = false;
    let test_batches = test_samples / batch_size;

    for epoch in 0..max_epochs {
        let epoch_start = Instant::now();
        let mut epoch_loss_sum = 0.0;

        // è®­ç»ƒ
        for batch_idx in 0..num_batches {
            let start = batch_idx * batch_size;
            let end = start + batch_size;

            let batch_images = tensor_slice!(all_train_images, start..end, ..);
            let batch_labels = tensor_slice!(all_train_labels, start..end, ..);

            // ä½¿ç”¨ V2 API è®¾ç½®è¾“å…¥
            x.set_value(&batch_images)?;
            y.set_value(&batch_labels)?;

            // æ¸…ç©ºæ¢¯åº¦
            optimizer.zero_grad()?;

            // åå‘ä¼ æ’­ï¼ˆV2 APIï¼šbackward ä¼šè‡ªåŠ¨ forwardï¼‰
            let loss_val = loss.backward()?;

            // æ›´æ–°å‚æ•°
            optimizer.step()?;

            epoch_loss_sum += loss_val;
        }

        let epoch_avg_loss = epoch_loss_sum / num_batches as f32;

        // æµ‹è¯•ç²¾åº¦
        let mut correct = 0;

        for batch_idx in 0..test_batches {
            let start = batch_idx * batch_size;
            let end = start + batch_size;

            let batch_images = tensor_slice!(all_test_images, start..end, ..);
            let batch_labels = tensor_slice!(all_test_labels, start..end, ..);

            x.set_value(&batch_images)?;
            y.set_value(&batch_labels)?;

            // å‰å‘ä¼ æ’­
            logits.forward()?;

            let predictions = logits.value()?.unwrap();

            for i in 0..batch_size {
                let mut pred_class = 0;
                let mut max_val = f32::NEG_INFINITY;
                for j in 0..10 {
                    let val = predictions[[i, j]];
                    if val > max_val {
                        max_val = val;
                        pred_class = j;
                    }
                }

                let mut true_class = 0;
                for j in 0..10 {
                    if batch_labels[[i, j]] > 0.5 {
                        true_class = j;
                        break;
                    }
                }

                if pred_class == true_class {
                    correct += 1;
                }
            }
        }

        let total_tested = test_batches * batch_size;
        let accuracy = correct as f32 / total_tested as f32;

        println!(
            "Epoch {:2}/{}: loss = {:.4}, å‡†ç¡®ç‡ = {:.1}% ({}/{}), è€—æ—¶ {:.2}s",
            epoch + 1,
            max_epochs,
            epoch_avg_loss,
            accuracy * 100.0,
            correct,
            total_tested,
            epoch_start.elapsed().as_secs_f32()
        );

        if accuracy >= target_accuracy {
            consecutive_success_count += 1;
            if consecutive_success_count >= consecutive_success_required {
                test_passed = true;
                println!(
                    "\nğŸ‰ è¿ç»­ {} æ¬¡è¾¾åˆ° {:.0}% ä»¥ä¸Šå‡†ç¡®ç‡ï¼",
                    consecutive_success_required,
                    target_accuracy * 100.0
                );
                break;
            }
        } else {
            consecutive_success_count = 0;
        }
    }

    let total_duration = start_time.elapsed();
    println!("\næ€»è€—æ—¶: {:.2}s", total_duration.as_secs_f32());

    if test_passed {
        println!("\n{}", "=".repeat(60));
        println!("âœ… MNIST Batch V2 æµ‹è¯•é€šè¿‡ï¼");
        println!("{}\n", "=".repeat(60));
        Ok(())
    } else {
        println!("\n{}", "=".repeat(60));
        println!(
            "âŒ æµ‹è¯•å¤±è´¥ï¼šåœ¨ {} ä¸ª epoch å†…æœªèƒ½è¿ç»­ {} æ¬¡è¾¾åˆ° {:.0}% å‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        );
        println!("{}\n", "=".repeat(60));
        Err(GraphError::ComputationError(format!(
            "MNIST Batch V2 æµ‹è¯•å¤±è´¥ï¼šåœ¨ {} ä¸ª epoch å†…æœªèƒ½è¿ç»­ {} æ¬¡è¾¾åˆ° {:.0}% å‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        )))
    }
}
