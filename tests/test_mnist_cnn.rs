/*
 * @Author       : è€è‘£
 * @Date         : 2025-12-22
 * @Description  : MNIST CNN é›†æˆæµ‹è¯•ï¼ˆå¯¹åº” MatrixSlow Chapter 8ï¼‰
 *                 éªŒè¯ï¼šConv2d + MaxPool2d + AvgPool2d + Linear Layer + Batch è®­ç»ƒ + Adam ä¼˜åŒ–å™¨
 *                 æž„å»º LeNet é£Žæ ¼ CNN è¿›è¡Œæ‰‹å†™æ•°å­—åˆ†ç±»
 *
 * æž¶æž„è¯´æ˜Žï¼š
 *   æœ¬æµ‹è¯•åŸºäºŽç»å…¸ LeNet-5 æž¶æž„ï¼Œä½†æœ‰ä»¥ä¸‹è°ƒæ•´ï¼š
 *   - LeNet-5 åŽŸå§‹è®¾è®¡ï¼ˆ1989, Yann LeCunï¼‰ä½¿ç”¨ **å¹³å‡æ± åŒ– (AvgPool)**
 *   - çŽ°ä»£ CNN å®žè·µä¸­å¸¸ç”¨ **æœ€å¤§æ± åŒ– (MaxPool)** ä»¥èŽ·å¾—æ›´å¥½çš„ç‰¹å¾æå–
 *   - æœ¬æµ‹è¯•åŒæ—¶ä½¿ç”¨ä¸¤ç§æ± åŒ–ï¼špool1 ç”¨ AvgPoolï¼ˆç»å…¸ï¼‰ï¼Œpool2 ç”¨ MaxPoolï¼ˆçŽ°ä»£ï¼‰
 *   - è¿™æ ·è®¾è®¡æ—¢è‡´æ•¬ç»å…¸ï¼ŒåˆéªŒè¯äº†ä¸¤ç§æ± åŒ–å±‚çš„æ­£ç¡®æ€§
 *
 * LeNet-5 åŽŸå§‹ç»“æž„å‚è€ƒï¼š
 *   C1(6@5x5) â†’ S2(AvgPool 2x2) â†’ C3(16@5x5) â†’ S4(AvgPool 2x2) â†’ FC(120) â†’ FC(84) â†’ Output(10)
 */

use only_torch::data::MnistDataset;
use only_torch::nn::layer::{avg_pool2d, conv2d, linear, max_pool2d};
use only_torch::nn::optimizer::{Adam, Optimizer};
use only_torch::nn::{Graph, GraphError};
use only_torch::tensor::Tensor;
use std::fs;
use std::time::Instant;

/// MNIST CNN é›†æˆæµ‹è¯•
///
/// ä½¿ç”¨ conv2d + avg_pool2d + max_pool2d + linear æž„å»º LeNet é£Žæ ¼ CNN
/// éªŒè¯æ‰€æœ‰ CNN Layer API çš„æ­£ç¡®æ€§
///
/// ç½‘ç»œç»“æž„ï¼ˆåŸºäºŽ LeNet-5ï¼ŒåŒæ—¶æµ‹è¯•ä¸¤ç§æ± åŒ–ï¼‰ï¼š
/// ```text
/// Input [batch, 1, 28, 28]
///     â†“
/// conv1 (1â†’8, 5x5, pad=2) â†’ ReLU â†’ [batch, 8, 28, 28]
///     â†“
/// avg_pool1 (2x2, stride=2) â†’ [batch, 8, 14, 14]    â† ç»å…¸ LeNet é£Žæ ¼ (AvgPool)
///     â†“
/// conv2 (8â†’16, 3x3, pad=1) â†’ ReLU â†’ [batch, 16, 14, 14]
///     â†“
/// max_pool2 (2x2, stride=2) â†’ [batch, 16, 7, 7]    â† çŽ°ä»£ CNN é£Žæ ¼ (MaxPool)
///     â†“
/// flatten â†’ [batch, 784]
///     â†“
/// fc1 (784 â†’ 64) â†’ ReLU
///     â†“
/// fc2 (64 â†’ 10) â†’ SoftmaxCrossEntropy
/// ```
#[test]
#[cfg_attr(debug_assertions, ignore)]
fn test_mnist_cnn() -> Result<(), GraphError> {
    let start_time = Instant::now();

    println!("\n{}", "=".repeat(60));
    println!("=== MNIST CNN é›†æˆæµ‹è¯•ï¼ˆLeNet é£Žæ ¼ï¼‰===");
    println!("{}\n", "=".repeat(60));

    // ========== 1. åŠ è½½æ•°æ® ==========
    println!("[1/4] åŠ è½½ MNIST æ•°æ®é›†...");
    let load_start = Instant::now();

    let train_data = MnistDataset::train().expect("åŠ è½½ MNIST è®­ç»ƒé›†å¤±è´¥");
    let test_data = MnistDataset::test().expect("åŠ è½½ MNIST æµ‹è¯•é›†å¤±è´¥");
    // æ³¨æ„ï¼šCNN éœ€è¦ [N, C, H, W] æ ¼å¼ï¼Œä¸ flatten

    println!(
        "  âœ“ è®­ç»ƒé›†: {} æ ·æœ¬ï¼Œæµ‹è¯•é›†: {} æ ·æœ¬ï¼Œè€—æ—¶ {:.2}s",
        train_data.len(),
        test_data.len(),
        load_start.elapsed().as_secs_f32()
    );

    // ========== 2. è®­ç»ƒé…ç½®ï¼ˆä¸Ž test_mnist_batch.rs ä¿æŒä¸€è‡´ï¼‰==========
    let batch_size = 512;
    let train_samples = 5000;
    let test_samples = 1000;
    let max_epochs = 15;
    let num_batches = train_samples / batch_size;
    let learning_rate = 0.008; // çº¿æ€§ç¼©æ”¾ï¼šbatch_size Ã—8ï¼Œlr Ã—8
    let target_accuracy = 0.90; // 90% å‡†ç¡®çŽ‡ç›®æ ‡
    let consecutive_success_required = 2;

    println!("\n[2/4] è®­ç»ƒé…ç½®ï¼š");
    println!("  - Batch Size: {}", batch_size);
    println!(
        "  - è®­ç»ƒæ ·æœ¬: {} (å…± {} ä¸ª batch)",
        train_samples, num_batches
    );
    println!("  - æµ‹è¯•æ ·æœ¬: {}", test_samples);
    println!("  - æœ€å¤§ Epochs: {}", max_epochs);
    println!("  - å­¦ä¹ çŽ‡: {}", learning_rate);
    println!("  - ç›®æ ‡å‡†ç¡®çŽ‡: {:.0}%", target_accuracy * 100.0);

    // ========== 3. æž„å»º CNN ç½‘ç»œ ==========
    println!("\n[3/4] æž„å»º LeNet é£Žæ ¼ CNN...");
    let build_start = Instant::now();

    let mut graph = Graph::new_with_seed(42);

    // è¾“å…¥èŠ‚ç‚¹: [batch, 1, 28, 28]
    let x = graph.new_input_node(&[batch_size, 1, 28, 28], Some("x"))?;
    // æ ‡ç­¾èŠ‚ç‚¹: [batch, 10]
    let y = graph.new_input_node(&[batch_size, 10], Some("y"))?;

    // ========== å·ç§¯å±‚ 1 ==========
    // conv1: 1â†’8 é€šé“, 5x5 æ ¸, padding=2 (same padding)
    let conv1 = conv2d(&mut graph, x, 1, 8, (5, 5), (1, 1), (2, 2), Some("conv1"))?;
    // conv1 è¾“å‡º: [batch, 8, 28, 28]
    let relu1 = graph.new_leaky_relu_node(conv1.output, 0.0, Some("relu1"))?;

    // pool1: 2x2, stride=2 â€”â€” ä½¿ç”¨ AvgPoolï¼ˆç»å…¸ LeNet-5 é£Žæ ¼ï¼‰
    let pool1 = avg_pool2d(&mut graph, relu1, (2, 2), Some((2, 2)), Some("avg_pool1"))?;
    // pool1 è¾“å‡º: [batch, 8, 14, 14]

    // ========== å·ç§¯å±‚ 2 ==========
    // conv2: 8â†’16 é€šé“, 3x3 æ ¸, padding=1 (same padding)
    let conv2 = conv2d(
        &mut graph,
        pool1.output,
        8,
        16,
        (3, 3),
        (1, 1),
        (1, 1),
        Some("conv2"),
    )?;
    // conv2 è¾“å‡º: [batch, 16, 14, 14]
    let relu2 = graph.new_leaky_relu_node(conv2.output, 0.0, Some("relu2"))?;

    // pool2: 2x2, stride=2 â€”â€” ä½¿ç”¨ MaxPoolï¼ˆçŽ°ä»£ CNN é£Žæ ¼ï¼‰
    let pool2 = max_pool2d(&mut graph, relu2, (2, 2), Some((2, 2)), Some("max_pool2"))?;
    // pool2 è¾“å‡º: [batch, 16, 7, 7]

    // ========== å±•å¹³ + å…¨è¿žæŽ¥å±‚ ==========
    // flatten: [batch, 16, 7, 7] â†’ [batch, 784]
    let flat = graph.new_flatten_node(pool2.output, true, Some("flatten"))?;

    // fc1: 784 â†’ 64
    let fc1 = linear(&mut graph, flat, 784, 64, batch_size, Some("fc1"))?;
    let relu3 = graph.new_leaky_relu_node(fc1.output, 0.0, Some("relu3"))?;

    // fc2: 64 â†’ 10 (è¾“å‡ºå±‚)
    let fc2 = linear(&mut graph, relu3, 64, 10, batch_size, Some("fc2"))?;
    let logits = fc2.output;

    // æŸå¤±å‡½æ•°
    let loss = graph.new_softmax_cross_entropy_node(logits, y, Some("loss"))?;

    println!(
        "  âœ“ CNN æž„å»ºå®Œæˆï¼Œè€—æ—¶ {:.2}s",
        build_start.elapsed().as_secs_f32()
    );
    println!("  ç½‘ç»œç»“æž„ï¼ˆåŸºäºŽ LeNet-5ï¼Œæ··åˆä¸¤ç§æ± åŒ–ï¼‰ï¼š");
    println!("    Input [batch, 1, 28, 28]");
    println!("      â†’ Conv1 (1â†’8, 5x5, bias) â†’ ReLU â†’ AvgPool (2x2)  [ç»å…¸]");
    println!("      â†’ Conv2 (8â†’16, 3x3, bias) â†’ ReLU â†’ MaxPool (2x2) [çŽ°ä»£]");
    println!("      â†’ Flatten â†’ FC1 (784â†’64) â†’ ReLU â†’ FC2 (64â†’10)");
    println!("      â†’ SoftmaxCrossEntropy");

    // ä¿å­˜ç½‘ç»œç»“æž„å¯è§†åŒ–ï¼ˆè®­ç»ƒå‰ï¼‰
    let output_dir = "tests/outputs";
    fs::create_dir_all(output_dir).ok();
    graph.save_visualization_grouped(&format!("{}/mnist_cnn", output_dir), None)?;
    graph.save_summary(&format!("{}/mnist_cnn_summary.md", output_dir))?;
    println!("  âœ“ ç½‘ç»œç»“æž„å·²ä¿å­˜: {}/mnist_cnn.png", output_dir);

    // ========== 4. è®­ç»ƒå¾ªçŽ¯ ==========
    println!("\n[4/4] å¼€å§‹è®­ç»ƒ...\n");

    let mut optimizer = Adam::new(&graph, learning_rate, 0.9, 0.999, 1e-8)?;

    // èŽ·å–å›¾åƒæ•°æ®ï¼ˆä¿æŒ [N, 1, 28, 28] æ ¼å¼ï¼‰
    let all_train_images = train_data.images(); // [N, 1, 28, 28]
    let all_train_labels = train_data.labels(); // [N, 10]
    let all_test_images = test_data.images();
    let all_test_labels = test_data.labels();

    let mut consecutive_success_count = 0;
    let mut test_passed = false;
    let test_batches = test_samples / batch_size;

    for epoch in 0..max_epochs {
        let epoch_start = Instant::now();
        let mut epoch_loss_sum = 0.0;

        // è®­ç»ƒ
        for batch_idx in 0..num_batches {
            let start = batch_idx * batch_size;
            let end = start + batch_size;

            // æå– batch æ•°æ®
            let batch_images = extract_batch_4d(&all_train_images, start, end, batch_size);
            let batch_labels = extract_batch_2d(&all_train_labels, start, end, batch_size);

            graph.set_node_value(x, Some(&batch_images))?;
            graph.set_node_value(y, Some(&batch_labels))?;

            optimizer.one_step_batch(&mut graph, loss)?;
            optimizer.update_batch(&mut graph)?;

            let loss_val = graph.get_node_value(loss)?.unwrap()[[0, 0]];
            epoch_loss_sum += loss_val;
        }

        let epoch_avg_loss = epoch_loss_sum / num_batches as f32;

        // æµ‹è¯•ç²¾åº¦
        graph.set_eval_mode();
        let mut correct = 0;

        for batch_idx in 0..test_batches {
            let start = batch_idx * batch_size;
            let end = start + batch_size;

            let batch_images = extract_batch_4d(&all_test_images, start, end, batch_size);
            let batch_labels = extract_batch_2d(&all_test_labels, start, end, batch_size);

            graph.set_node_value(x, Some(&batch_images))?;
            graph.set_node_value(y, Some(&batch_labels))?;

            graph.forward_batch(loss)?;

            let predictions = graph.get_node_value(logits)?.unwrap();

            for i in 0..batch_size {
                let mut pred_class = 0;
                let mut max_val = f32::NEG_INFINITY;
                for j in 0..10 {
                    let val = predictions[[i, j]];
                    if val > max_val {
                        max_val = val;
                        pred_class = j;
                    }
                }

                let mut true_class = 0;
                for j in 0..10 {
                    if batch_labels[[i, j]] > 0.5 {
                        true_class = j;
                        break;
                    }
                }

                if pred_class == true_class {
                    correct += 1;
                }
            }
        }

        graph.set_train_mode();

        let total_tested = test_batches * batch_size;
        let accuracy = correct as f32 / total_tested as f32;

        println!(
            "Epoch {:2}/{}: loss = {:.4}, å‡†ç¡®çŽ‡ = {:.1}% ({}/{}), è€—æ—¶ {:.2}s",
            epoch + 1,
            max_epochs,
            epoch_avg_loss,
            accuracy * 100.0,
            correct,
            total_tested,
            epoch_start.elapsed().as_secs_f32()
        );

        if accuracy >= target_accuracy {
            consecutive_success_count += 1;
            if consecutive_success_count >= consecutive_success_required {
                test_passed = true;
                println!(
                    "\nðŸŽ‰ è¿žç»­ {} æ¬¡è¾¾åˆ° {:.0}% ä»¥ä¸Šå‡†ç¡®çŽ‡ï¼",
                    consecutive_success_required,
                    target_accuracy * 100.0
                );
                break;
            }
        } else {
            consecutive_success_count = 0;
        }
    }

    let total_duration = start_time.elapsed();
    println!("\næ€»è€—æ—¶: {:.2}s", total_duration.as_secs_f32());

    // æ‰“å°æ¨¡åž‹æ‘˜è¦
    println!("\næ¨¡åž‹æ‘˜è¦ï¼š");
    graph.summary();

    if test_passed {
        println!("\n{}", "=".repeat(60));
        println!("âœ… MNIST CNN æµ‹è¯•é€šè¿‡ï¼");
        println!("{}\n", "=".repeat(60));
        Ok(())
    } else {
        println!("\n{}", "=".repeat(60));
        println!(
            "âŒ æµ‹è¯•å¤±è´¥ï¼šåœ¨ {} ä¸ª epoch å†…æœªèƒ½è¿žç»­ {} æ¬¡è¾¾åˆ° {:.0}% å‡†ç¡®çŽ‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        );
        println!("{}\n", "=".repeat(60));
        Err(GraphError::ComputationError(format!(
            "MNIST CNN æµ‹è¯•å¤±è´¥ï¼šåœ¨ {} ä¸ª epoch å†…æœªèƒ½è¿žç»­ {} æ¬¡è¾¾åˆ° {:.0}% å‡†ç¡®çŽ‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        )))
    }
}

/// ä»Ž 4D å¼ é‡ä¸­æå– batchï¼ˆæ‰‹åŠ¨å®žçŽ°ï¼Œé¿å…å®ä¾èµ–é—®é¢˜ï¼‰
fn extract_batch_4d(tensor: &Tensor, start: usize, end: usize, batch_size: usize) -> Tensor {
    let shape = tensor.shape();
    let c = shape[1];
    let h = shape[2];
    let w = shape[3];

    let mut data = Vec::with_capacity(batch_size * c * h * w);

    for n in start..end {
        for ci in 0..c {
            for hi in 0..h {
                for wi in 0..w {
                    data.push(tensor[[n, ci, hi, wi]]);
                }
            }
        }
    }

    Tensor::new(&data, &[batch_size, c, h, w])
}

/// ä»Ž 2D å¼ é‡ä¸­æå– batch
fn extract_batch_2d(tensor: &Tensor, start: usize, end: usize, batch_size: usize) -> Tensor {
    let shape = tensor.shape();
    let cols = shape[1];

    let mut data = Vec::with_capacity(batch_size * cols);

    for n in start..end {
        for j in 0..cols {
            data.push(tensor[[n, j]]);
        }
    }

    Tensor::new(&data, &[batch_size, cols])
}
