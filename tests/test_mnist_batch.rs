/*
 * @Author       : è€è‘£
 * @Date         : 2025-12-21
 * @Description  : MNIST Batch æœºåˆ¶é›†æˆæµ‹è¯•
 *                 éªŒè¯ï¼šbatch forward/backward + Adam ä¼˜åŒ–å™¨çš„é«˜æ•ˆè®­ç»ƒ
 *                 ä½¿ç”¨ MatMul å®ç° bias å¹¿æ’­ï¼ˆones @ biasï¼‰
 * @LastEditors  : è€è‘£
 * @LastEditTime : 2025-12-21
 */

use only_torch::data::MnistDataset;
use only_torch::nn::optimizer::{Adam, Optimizer};
use only_torch::nn::{Graph, GraphError};
use only_torch::tensor::Tensor;
use only_torch::tensor_slice;
use std::time::Instant;

/// MNIST Batch é›†æˆæµ‹è¯•
///
/// ä½¿ç”¨æ‰¹é‡æœºåˆ¶è®­ç»ƒ MLPï¼ˆå« biasï¼‰ï¼ŒéªŒè¯å‡†ç¡®ç‡è¾¾åˆ°ç›®æ ‡
#[test]
fn test_mnist_batch() -> Result<(), GraphError> {
    let start_time = Instant::now();

    println!("\n{}", "=".repeat(60));
    println!("=== MNIST Batch é›†æˆæµ‹è¯•ï¼ˆå« biasï¼‰===");
    println!("{}\n", "=".repeat(60));

    // ========== 1. åŠ è½½æ•°æ® ==========
    println!("[1/4] åŠ è½½ MNIST æ•°æ®é›†...");
    let load_start = Instant::now();

    let train_data = MnistDataset::train()
        .expect("åŠ è½½ MNIST è®­ç»ƒé›†å¤±è´¥")
        .flatten();
    let test_data = MnistDataset::test()
        .expect("åŠ è½½ MNIST æµ‹è¯•é›†å¤±è´¥")
        .flatten();

    println!(
        "  âœ“ è®­ç»ƒé›†: {} æ ·æœ¬ï¼Œæµ‹è¯•é›†: {} æ ·æœ¬ï¼Œè€—æ—¶ {:.2}s",
        train_data.len(),
        test_data.len(),
        load_start.elapsed().as_secs_f32()
    );

    // ========== 2. è®­ç»ƒé…ç½® ==========
    // batch_size=512 æ˜¯æœ€ä½³å¹³è¡¡ç‚¹ï¼šæ¯”åŸå§‹ 64 å¿« 70%ï¼Œä¸”æ— éœ€å¢åŠ æ•°æ®é‡
    let batch_size = 512;
    let train_samples = 5000;
    let test_samples = 1000;
    let max_epochs = 15;
    let num_batches = train_samples / batch_size;
    let learning_rate = 0.008; // çº¿æ€§ç¼©æ”¾ï¼šbatch_size Ã—8ï¼Œlr Ã—8
    let target_accuracy = 0.90; // 90% å‡†ç¡®ç‡ç›®æ ‡
    let consecutive_success_required = 2;

    println!("\n[2/4] è®­ç»ƒé…ç½®ï¼š");
    println!("  - Batch Size: {batch_size}");
    println!("  - è®­ç»ƒæ ·æœ¬: {train_samples} (å…± {num_batches} ä¸ª batch)");
    println!("  - æµ‹è¯•æ ·æœ¬: {test_samples}");
    println!("  - æœ€å¤§ Epochs: {max_epochs}");
    println!("  - å­¦ä¹ ç‡: {learning_rate}");
    println!("  - ç›®æ ‡å‡†ç¡®ç‡: {:.0}%", target_accuracy * 100.0);

    // ========== 3. æ„å»ºç½‘ç»œ ==========
    println!("\n[3/4] æ„å»º MLP ç½‘ç»œ: 784 -> 128 (Sigmoid+bias) -> 10 (bias)...");

    let mut graph = Graph::new_with_seed(42);

    // è¾“å…¥/æ ‡ç­¾èŠ‚ç‚¹ï¼ˆbatch ç»´åº¦ï¼‰
    let x = graph.new_input_node(&[batch_size, 784], Some("x"))?;
    let y = graph.new_input_node(&[batch_size, 10], Some("y"))?;

    // ç”¨äº bias å¹¿æ’­çš„ ones çŸ©é˜µ [batch_size, 1]
    let ones = graph.new_input_node(&[batch_size, 1], Some("ones"))?;

    // éšè—å±‚ï¼š784 -> 128ï¼ˆä½¿ç”¨ ones @ b1 å®ç° bias å¹¿æ’­ï¼‰
    let w1 = graph.new_parameter_node_seeded(&[784, 128], Some("w1"), 42)?;
    let b1 = graph.new_parameter_node_seeded(&[1, 128], Some("b1"), 43)?;
    let z1 = graph.new_mat_mul_node(x, w1, None)?; // [batch, 784] @ [784, 128] = [batch, 128]
    let b1_broadcast = graph.new_mat_mul_node(ones, b1, None)?; // [batch, 1] @ [1, 128] = [batch, 128]
    let h1 = graph.new_add_node(&[z1, b1_broadcast], None)?; // [batch, 128] + [batch, 128]
    let a1 = graph.new_sigmoid_node(h1, None)?;

    // è¾“å‡ºå±‚ï¼š128 -> 10
    let w2 = graph.new_parameter_node_seeded(&[128, 10], Some("w2"), 44)?;
    let b2 = graph.new_parameter_node_seeded(&[1, 10], Some("b2"), 45)?;
    let z2 = graph.new_mat_mul_node(a1, w2, None)?; // [batch, 128] @ [128, 10] = [batch, 10]
    let b2_broadcast = graph.new_mat_mul_node(ones, b2, None)?; // [batch, 1] @ [1, 10] = [batch, 10]
    let logits = graph.new_add_node(&[z2, b2_broadcast], None)?; // [batch, 10] + [batch, 10]

    // æŸå¤±å‡½æ•°
    let loss = graph.new_softmax_cross_entropy_node(logits, y, Some("loss"))?;

    println!("  âœ“ ç½‘ç»œæ„å»ºå®Œæˆï¼ˆå« bias å¹¿æ’­ï¼‰");

    // ========== 4. è®­ç»ƒå¾ªç¯ ==========
    println!("\n[4/4] å¼€å§‹è®­ç»ƒ...\n");

    let mut optimizer = Adam::new(&graph, learning_rate, 0.9, 0.999, 1e-8)?;

    // è®¾ç½® ones çŸ©é˜µï¼ˆå…¨ 1ï¼‰
    let ones_tensor = Tensor::ones(&[batch_size, 1]);
    graph.set_node_value(ones, Some(&ones_tensor))?;

    let all_train_images = train_data.images();
    let all_train_labels = train_data.labels();
    let all_test_images = test_data.images();
    let all_test_labels = test_data.labels();

    let mut consecutive_success_count = 0;
    let mut test_passed = false;
    let test_batches = test_samples / batch_size;

    for epoch in 0..max_epochs {
        let epoch_start = Instant::now();
        let mut epoch_loss_sum = 0.0;

        // è®­ç»ƒ
        for batch_idx in 0..num_batches {
            let start = batch_idx * batch_size;
            let end = start + batch_size;

            let batch_images = tensor_slice!(all_train_images, start..end, ..);
            let batch_labels = tensor_slice!(all_train_labels, start..end, ..);

            graph.set_node_value(x, Some(&batch_images))?;
            graph.set_node_value(y, Some(&batch_labels))?;

            graph.zero_grad()?;
            graph.forward(loss)?;
            let loss_val = graph.backward(loss)?; // backward è¿”å› loss å€¼
            optimizer.step(&mut graph)?;

            epoch_loss_sum += loss_val;
        }

        let epoch_avg_loss = epoch_loss_sum / num_batches as f32;

        // æµ‹è¯•ç²¾åº¦
        graph.set_eval_mode();
        let mut correct = 0;

        for batch_idx in 0..test_batches {
            let start = batch_idx * batch_size;
            let end = start + batch_size;

            let batch_images = tensor_slice!(all_test_images, start..end, ..);
            let batch_labels = tensor_slice!(all_test_labels, start..end, ..);

            graph.set_node_value(x, Some(&batch_images))?;
            graph.set_node_value(y, Some(&batch_labels))?;

            graph.forward(loss)?;

            let predictions = graph.get_node_value(logits)?.unwrap();

            for i in 0..batch_size {
                // é¢„æµ‹ç±»åˆ«
                let mut pred_class = 0;
                let mut max_val = f32::NEG_INFINITY;
                for j in 0..10 {
                    let val = predictions[[i, j]];
                    if val > max_val {
                        max_val = val;
                        pred_class = j;
                    }
                }

                // å®é™…ç±»åˆ«
                let mut true_class = 0;
                for j in 0..10 {
                    if batch_labels[[i, j]] > 0.5 {
                        true_class = j;
                        break;
                    }
                }

                if pred_class == true_class {
                    correct += 1;
                }
            }
        }

        graph.set_train_mode();

        let total_tested = test_batches * batch_size;
        let accuracy = correct as f32 / total_tested as f32;

        println!(
            "Epoch {:2}/{}: loss = {:.4}, å‡†ç¡®ç‡ = {:.1}% ({}/{}), è€—æ—¶ {:.2}s",
            epoch + 1,
            max_epochs,
            epoch_avg_loss,
            accuracy * 100.0,
            correct,
            total_tested,
            epoch_start.elapsed().as_secs_f32()
        );

        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡
        if accuracy >= target_accuracy {
            consecutive_success_count += 1;
            if consecutive_success_count >= consecutive_success_required {
                test_passed = true;
                println!(
                    "\nğŸ‰ è¿ç»­ {} æ¬¡è¾¾åˆ° {:.0}% ä»¥ä¸Šå‡†ç¡®ç‡ï¼",
                    consecutive_success_required,
                    target_accuracy * 100.0
                );
                break;
            }
        } else {
            consecutive_success_count = 0;
        }
    }

    let total_duration = start_time.elapsed();
    println!("\næ€»è€—æ—¶: {:.2}s", total_duration.as_secs_f32());

    if test_passed {
        println!("\n{}", "=".repeat(60));
        println!("âœ… MNIST Batch æµ‹è¯•é€šè¿‡ï¼");
        println!("{}\n", "=".repeat(60));
        Ok(())
    } else {
        println!("\n{}", "=".repeat(60));
        println!(
            "âŒ æµ‹è¯•å¤±è´¥ï¼šåœ¨ {} ä¸ª epoch å†…æœªèƒ½è¿ç»­ {} æ¬¡è¾¾åˆ° {:.0}% å‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        );
        println!("{}\n", "=".repeat(60));
        Err(GraphError::ComputationError(format!(
            "MNIST Batch æµ‹è¯•å¤±è´¥ï¼šåœ¨ {} ä¸ª epoch å†…æœªèƒ½è¿ç»­ {} æ¬¡è¾¾åˆ° {:.0}% å‡†ç¡®ç‡",
            max_epochs,
            consecutive_success_required,
            target_accuracy * 100.0
        )))
    }
}
